---
title: 15-445 数据库项目总结
date: 2022-03-05 21:02:09
tags: 
    - Database System
    - 面试
    - 项目
mathjax: true
categories: 项目
---

**15-445项目要点总结**

<!--more-->

# Project 1 Buffer Pool

## 整体功能需求

- **内存管理**：实现Buffer Pool，正确处理创建页面、获取页面、释放页面、删除页面、将页面写回磁盘等请求操作
- **页面置换**：当线程请求页面，而内存中页面已用完（`free_list`为空），则应该使用LRU策略将一个当前未被任何线程使用的页面写回磁盘，并释放其空间用于保存新页面
- 保证Buffer Pool的**线程安全**：当多个线程同时请求访问Buffer Pool时，一次只有一个线程能获得其访问权，采用锁进行保护
- **提高Buffer Pool的并发度**：单个`BufferPoolManagerInstance`一次只能请求一个线程的页面请求，为了提高并发度，使用多个`BufferPoolManagerInstance`组成buffer pool，每个都管理着一段独立的内存空间，从而可以同时处理多个线程的页面请求

## Task1 LRU替换策略

### 功能需求

- 实现一个基于LRU算法的LRU_replacer，即在需要进行页面置换时候，决定将内存中哪个页面置换到外存的replacer

### 数据结构与算法设计

- LRU算法的实现，若要实现`O(1)`时间内的读写，可使用**双向链表 + 哈希表**的形式
- 使用**双向链表**`buffer_`保存当前的空闲页面，刚加入的页面将放在链表末尾，因此越靠近首端的页面则越久未被使用，当调用`Victim`置换页面时，位于链表首段的页面将被替换
- 使用**哈希表**`f_`保存当前LRUReplacer中页面**在链表的迭代器**，因此当Buffer Pool管理器调用`Pin`获取某个页面时，可以在`O(1)`时间内将该页面从链表中移除

### 成员函数设计

- `LRUReplacer(size_t num_pages)`

  创建一个大小为`num_pages`的LRUReplacer，`num_pages`代表Buffer Pool的页面总数

- `Victim(frame_id_t *frame_id)`

  - 根据LRU策略从当前的可替换页面中选取一个，并将其从LRUreplacer中移除，将其页号存入指针`*frame_id`指向的位置，并返回true
  - 若当前LRUReplacer中没有可用的页面，则返回false

- `Pin(frame_id)`

  某个线程需要**读写该页面**，因此将其**从LRUReplacer中移除**

- `Unpin(frame_id)`

  当Buffer pool中某个页面的计数值为0，意味着当前**没有线程正在使用该页面**，因此它是可置换的，则调用`Unpin`将其**加入LRUReplacer中**

- `Size()`

  返回当前LRUReplacer中的**可置换页面数**

### 关键问题分析

- `Pin`和`Unpin`的含义？
  - `Pin`代表**某个线程需要使用某页面**，因此Buffer Pool向LRUReplacer获取该页面，此时需要将该页面从LRUReplacer中移除
  - `Unpin`代表当前**没有任何线程使用该页面**，因此Buffer Pool中该页面的计数值为0，它会调用`Unpin`将页面**加入LRUReplacer中**
- LRU策略的实现，运用了什么数据结构，为什么要使用？
  - 双向链表 + 哈希表，详见上述数据结构与算法分析
  - 使用**双向链表**是因为当**加入**某个页面时，将其**放在末尾**，则首端的页面自然就是最久未被使用的页面，从而在**页面置换时**候直接**移除链表首端的页面**即可，因此插入和删除的时间复杂度都是`O(1)`
  - 使用哈希表是因为除了上述情况，还可能**Buffer Pool调用`Pin`获取某个页面**，此时该页面可能位于链表中间，**为了避免从头遍历链表**，我们将页号到链表迭代器的映射存放在哈希表，从而Buffer Pool获取某个页面时，可以在`O(1)`时间内**取得其迭代器**，并在`O(1)`时间内**将其从链表中移除**

### 实现

```c++
bool LRUReplacer::Victim(frame_id_t *frame_id) {
  std::unique_lock<std::mutex> guard(mtx_);
  if (f_.empty()) {
    return false;
  }
  *frame_id = *buffer_.begin();
  f_.erase(*buffer_.begin());
  buffer_.pop_front();
  return true;
}

void LRUReplacer::Pin(frame_id_t frame_id) {
  std::unique_lock<std::mutex> guard(mtx_);
  if (f_.count(frame_id)) {
    buffer_.erase(f_[frame_id]);
    f_.erase(frame_id);
  }
}

void LRUReplacer::Unpin(frame_id_t frame_id) {
  std::unique_lock<std::mutex> guard(mtx_);
  if (f_.count(frame_id)) {
    return;
  }
  buffer_.emplace_back(frame_id);
  f_[frame_id] = --buffer_.end();
}

size_t LRUReplacer::Size() {
  std::unique_lock<std::mutex> guard(mtx_);
  return buffer_.size();
}
```

### Debug过程

- 略

## Task2 Buffer Pool管理器

### 功能需求

- **从磁盘读取页面**：从`DiskManager`读取某个页面并存入内存
- **将页面写回磁盘**：当进行LRU页面置换，或数据库系统显式地要求将页面写回磁盘时，将dirty页面写回磁盘
-  **页面状态**：维护内存中各个页面的以下信息
  - **dirty标志位**，表明该页面是否被修改
  - **使用线程数**，表明该页面被多少个线程所使用
- **执行LRU页面置换**：如果线程向Buffer Pool Manager请求某个页面，而此时已没有空闲页，则它通过LRUReplacer选择一个Victim，并将该页面写回磁盘，从而得到一个空闲页

### 数据结构与算法设计

- **页表**：负责将内存中的页号映射到物理帧号

### 成员函数设计

- `FetchPgImp(page_id)`，**获取**某个页面

  - **查找页表**：在页表中查找该页面（P）
    - 如果P**存在**页表中，**Pin并返回其指针**
    - 如果P**不存在**，选择**受害页（R）**进行页面置换
  - **写磁盘**：如果R是dirty的，将其**写回磁盘**
  - **更新页表**：将**R从页表删除**，并将**P加入页表**
  - **更新P的metadata**：更新page_id、pin_count，从磁盘中读入其数据，
  - **返回**：指向P的指针

- `NewPgImp(page_id)`，**创建**一个页面

  - **没有空闲frame**：如果Buffer pool中所有页面都非空闲（即freelist和LRUReplacer都没有空闲页面），则返回`nullptr`
  - **获取空闲frame**：否则从free list或LRUReplacer获取一个frame
    - 若`free_list`非空则从`free_list`获取
    - 否则，调用LRUReplacer的`Victim`获取一个`frame_id`，调用`Pin`将其从LRUReplacer移除

  - **写磁盘**：检查该frame之前存放的页面是否dirty，若dirty则应先将其写回磁盘，将该frame存储的页对应的**表项从页表中移除**
  - **更新新页面的metadata**：调用`AllocatePage()`得到**新的页号**，将该页号到`frame_id`的映射**加入页表**，设置新页面的`pin_count=1`、并调用`ResetMemory()`初始化其数据
  - **返回**：返回新的**页号**、指向该新页面的**指针**

- `UnpinPgImp(page_id, is_dirty)`，线程调用该方法告知Buffer Pool自己不再使用该页面

  - **查找页表**：在页表中查找该页码，若不存在则返回true
  - **置脏位**：`is_dirty`代表调用该方法的线程是否修改了该页，注意不能直接将该值赋给页面的dirty位，只有当`is_dirty`**为true时才进行赋值**

  > 这是因为如果直接赋值，那么本来为脏的页面，会被没修改过该页的线程清除掉dirty标志，导致错误

  - **更新pin count**：将该页面的pin count减1，若变为0说明没有任何线程正使用该页面，则调用LRUReplacer的Unpin方法将其加入其中
  - 特别地，如果减1后pin count小于0，说明发生了错误，返回false

- `DeletePgImp(page_id)`，删除该页面

  - **查找**：查找页表，若没找到则返回true

  - **检查pin count**：如果找到了P，但是pin count非0，说明有线程正使用该页面，无法删除，返回false

  - **删除**：若pin count为0，则可以删除

    - 调用`DeallocatePage`将页号归还

    - 将P从页表中移除
    - 将P从LRUReplacer移除（如在）
    - 重置其metadata，并将其重新加入`free_list`

- `FlushPgImp(page_id)`，将该页面写回磁盘

  - **查找页表**：从页表中获取该页面的frame_id，若没找到则返回false
  - **写磁盘**：检查该页是否dirty，若是则将其写入磁盘，返回true

- `FlushAllPagesImpl()`，将所有页面写回磁盘

  - 对**页表中的每个页**都调用`FlushPgImp`即可

### 关键问题分析

- `Pin`和`Unpin`的含义
  - 此处的Pin指有线程想要使用该页面，因此pin count计数加1，并将该页面加入Buffer pool中；Unpin指有线程完成对该页面的使用，因此pin count减1，如果计数值为0还需要将其移出Buffer pool，加入LRUReplacer
  - 因此`Unpin`对LRUReplacer意味着加入页面，对Buffer pool可能意味着移除页面

### 实现

- 略

### Debug过程

- `DeletePgImp(page_id)`中应该调用LRUReplacer的`Unpin`成员将P从LRUReplacer移除（如在）
- `UnpinPgImp(page_id, is_dirty)`中的`is_dirty`只代表该线程是否修改过页面，不能直接将该值赋给页面的dirty位，只有当`is_dirty`**为true时才进行赋值**

## Task3 Parallel Buffer Pool管理器

### 功能需求

- 每个`BufferPoolManagerInstance`进行页面管理时都需要先获取互斥锁，因此同一时间一个`BufferPoolManagerInstance`只能处理一个线程的页面请求
- 为了提高并发度，可以在系统中设置多个`BufferPoolManagerInstance`，每个管理着一段内存空间，并拥有自己的互斥锁，假如Buffer pools的数量为m，则同时可以处理m个线程的页面管理请求
- 当线程请求分配或释放页面时，Buffer pool管理器会选择一个`BufferPoolManagerInstance`以处理该请求，对于页号为`page_id`的页面请求，交由`page_id % m`个`BufferPoolManagerInstance`进行处理

### 数据结构与算法设计

- **Round robin manner**
  - 当创建页面时（此时还未分配页号，因而理论上可以随意选取其中一个buffer pool），为了使得多个buffer pools的**内存使用尽量均衡**，根据**Round robin算法**选取其中一个buffer pools
  - 具体地，我们维护一个`start_index_`变量，作为每次执行`NewPgImp`的起始Buffer pool
  - 从该Buffer pool开始（即`bpms_[start_index]`），遍历每个buffer pool并尝试创建页面，如果该buffer pool有空闲页面则创建成功并返回页号、指向该页的指针
  - 如果该buffer pool没有空闲页面则返回`nullptr`此时我们循环遍历下一个buffer pool
  - 该过程持续直至回到开始的`bpms_[start_index]`，则说明此时整个buffer pool manager都没有空闲空间了，返回nullptr
  - 每次执行完该函数，都递增`start_index_`，因此下次创建页面将优先从下一个buffer pool开始分配页面
- `dynamic_cast`
  - 特别地，本题接口设计要求`GetBufferPoolManager`返回`BufferPoolManager*`，而我们实际上使用的是派生类指针`BufferPoolManagerInstance*`
  - 这里使用了C++11的类类型转换特性，可以通过`dynamic_cast`**将指向基类引用或指针强制转换为派生类引用或指针**，转换失败则返回0（指针类型）或抛出`bad_cast`异常（引用类型）

### 成员函数设计

- `BufferPoolManager* GetBufferPoolManager(page_id)`

  获取保存该页面的buffer pool，根据我们的分配策略，返回`bpms_[page_id % m]`

  ```c++
  BufferPoolManager *ParallelBufferPoolManager::GetBufferPoolManager(page_id_t page_id) {
    // Get BufferPoolManager responsible for handling given page id. You can use this method in your other methods.
    return bpms_[page_id % num_instances_];
  }
  ```

- `Page* NewPgImp(page_id_t *page_id)`

  根据“数据结构与算法设计”中的Round robin逻辑进行

  ```c++
  Page *ParallelBufferPoolManager::NewPgImp(page_id_t *page_id) {
    // create new page. We will request page allocation in a round robin manner from the underlying
    // BufferPoolManagerInstances
    // 1.   From a starting index of the BPMIs, call NewPageImpl until either 1) success and return 2) looped around to
    // starting index and return nullptr
    // 2.   Bump the starting index (mod number of instances) to start search at a different BPMI each time this function
    // is called
    if (num_instances_ == 0) {
      return nullptr;
    }
    std::unique_lock<std::mutex> guard(mtx_);
    for (size_t i = 0; i < num_instances_; i++) {
      size_t index = (start_index_ + i) % num_instances_;
      Page *p = dynamic_cast<BufferPoolManagerInstance *>(bpms_[index])->NewPage(page_id);
      if (p) {
        start_index_ = (start_index_ + 1) % num_instances_;
        return p;
      }
    }
    start_index_ = (start_index_ + 1) % num_instances_;
    return nullptr;
  }
  ```

- 对于其他成员，直接**调用**`BufferPoolManagerInstance`**的相应成员完成操作**即可

  ```c++
  Page *ParallelBufferPoolManager::FetchPgImp(page_id_t page_id) {
    // Fetch page for page_id from responsible BufferPoolManagerInstance
    return dynamic_cast<BufferPoolManagerInstance *>(GetBufferPoolManager(page_id))->FetchPage(page_id);
  }
  
  bool ParallelBufferPoolManager::UnpinPgImp(page_id_t page_id, bool is_dirty) {
    // Unpin page_id from responsible BufferPoolManagerInstance
    return dynamic_cast<BufferPoolManagerInstance *>(GetBufferPoolManager(page_id))->UnpinPage(page_id, is_dirty);
  }
  
  bool ParallelBufferPoolManager::FlushPgImp(page_id_t page_id) {
    // Flush page_id from responsible BufferPoolManagerInstance
    return dynamic_cast<BufferPoolManagerInstance *>(GetBufferPoolManager(page_id))->FlushPage(page_id);
  }
  
  bool ParallelBufferPoolManager::DeletePgImp(page_id_t page_id) {
    // Delete page_id from responsible BufferPoolManagerInstance
    return dynamic_cast<BufferPoolManagerInstance *>(GetBufferPoolManager(page_id))->DeletePage(page_id);
  }
  
  void ParallelBufferPoolManager::FlushAllPgsImp() {
    // flush all pages from all BufferPoolManagerInstances
    for (auto &p : bpms_) {
      dynamic_cast<BufferPoolManagerInstance *>(p)->FlushAllPages();
    }
  }
  ```

### 关键问题分析

- 无

### 实现

- 见成员函数设计

### Debug过程

- **正确模拟Round robin的行为**，仔细参考文档表述，`start_index_`只在每次执行`NewPgImp`的结尾加1，而不会随着遍历`bpm_`的过程变化

# Project 2 Extendible Hash Index

## 回顾：Hash Table基础知识

### 1 Data Structures

- 一个数据库管理系统可能使用许多数据结构，包括
  - Internal Meta-Data，用于存储数据库自身和系统状态等信息，如page table、page directory
  - Core Data Storage，用于存储数据库中的元组
  - Temporary Data Structures，DBMS可能通过临时数据结构以加速查询执行
  - Table Indices：**表索引**，用于快速查找特定的元组的辅助数据结构

### 2 Hash Table

- 哈希表由以下两部分组成
  - **哈希函数**：将一个较大的键空间映射为一个较小的域，需要考虑**执行速度**与**碰撞概率**之间的平衡
  - **哈希结构**：当发生哈希碰撞时如何处理

### 3 Hash Functions

- **输入**：任意键
- **输出**：哈希值，一个整数
- **特点**：**确定的函数**，即对于相同的键总是产生相同的哈希值
- **评估标准**：通过**计算速度、碰撞概率**评估哈希函数的性能

### 4 静态哈希方案

- **静态**：哈希表的大小是固定的
- **空间耗尽**：如果DBMS耗尽了哈希表的空间，则必须重建一个更大（通常为2倍大小）的哈希表，重建的代价是高昂的
- **哈希碰撞**：为了减少哈希碰撞，通常将**哈希槽的数量**设为可能存储的**元素个数的两倍**
- **缺点**：现实中，难以事先知道需要存储的元素数量

#### 4.1 线性样本哈希Linear Probe Hashing

- **插入**：
  - 散列：使用循环的槽序列，哈希函数将key映射为某个槽
  - 哈希碰撞：当哈希碰撞发生时，线性扫描相邻的下一个槽，直至找到空的槽
- **查找**：首先查找key的哈希值对应的槽，若没找到则线性扫描直至找到该项，或者到达一个空的槽（意味着key不在哈希表中），这意味着我们必须把存储的每个键都存储在槽中
- **删除**：我们不能直接移除一个项，否则可能使得之后的查询出错（因为查找时遇到空槽就停下并认为key不在哈希表中），解决方法
  - **方法1，使用“墓碑”**：删除时在槽中放置“墓碑”，查找遇到“墓碑”时不能认为其是空槽而停下，应该继续遍历
  - **方法2，将相邻的数据移动到空槽中**：我们必须标记哪些项是插入时移动过的，只能移动那些初始移动过的项，且移动是循环进行的

- **非唯一键**：如果相同的键可能与多个不同的值或元组关联，则
  - **链表**：槽中不存储值，而是存储一个指向链表的指针，该链表存放与该键关联的所有值
  - **重复键**：允许重复存储相同的键，仍然按上述单一键的规则进行增删查找

#### 4.2 罗宾汉散列Robin Hood Hashing

- **目标**：最小化各个键存储位置与其**最优位置**（根据哈希函数计算得到的槽）的距离
- **距离**：每个项不但记录其键、值，还记录其**当前位置与最优位置的距离**$d$
- **插入**：若当前插入的项$i$移动到某个槽时，其距离为$d_i$，而当前槽中项$j$的距离为$d_j$，若$d_i \gt d_j$，则将项$i$**替换**项$j$，项$i$插入该槽，项$j$继续线性扫描直到找到可插入的槽

### 5 动态哈希方案

- **静态**哈希方案扩容时必须**重建整个哈希表**，**动态**哈希表能够**根据需求调整哈希表大小**，而不用重建整个哈希表

#### 5.1 Chained Hashing

- 每个槽都对应一个**链表**，映射到相同槽的键将被存储在该槽的链表

#### 5.2 Extendible Hashing

- **散列函数**：将键映射为一个b位二进制数，如`b=32`
- **深度**：查找数据时需要使用的散列值位数
  - 全局深度$i$，根据散列值的前$i$位找到某个桶
  - 局部深度$i_j$，某个桶的深度，满足$i_j \leq i$
  - 指向某个桶的槽的数量为$2^{i-i_j}$

- **桶分裂**
  - Chained hashing中链表可能无限增长，Extendible hashing会在必要时进行桶分裂
  - 当桶满了后，进行桶分裂，打乱其数据并放入两个桶中，桶的局部深度递增

## Task1 Page Layouts

### 数据成员设计

- **Hash Table Directory Page**，保存了所有哈希表的元数据，包括
  - `page_id_`，该目录页本身的page id
  - `lsn_`，记录的序列号
  - `global_depth`，当前目录的全局深度
  - `local_depths`，存放了各个桶的局部深度的数组
  - `bucket_page_ids_`，存放了各个桶的页号的数组，`bucket_page_ids[i]`含义是第 i个桶页的页号
- **Hash Table Bucket Page**
  - `occupied_`数组，代表该桶的第i个位置是否被占据
  - `readable_`数组，代表该桶的第i个位置是否可读
  - `array_`数组，存储着键值对

### 关键问题分析

- `occupied_`与`readable_`数组的含义区别？

  - **thumb stone**：根据Linear Probe Hash的原理，为了保证查找结果的正确性，我们在移除项时应该放置**thumb stone**来进行标记
  - `occupied_`代表该项要么拥有一个有效数据项，要么放置了一个thumb stone；而`readable_`代表该项有一个有效数据项
  - **删除数据**：移除元素时我们应该清除`readable_`数组的对应位，而`occupied_`数组无需清除
  - **查找数据**：只查找`readable_`位为1的位置
  - **插入数据**：只要该位的`readable_`位为0，就认为它是空位

  > 事实上，`occupied_`在本实验中是无用的，因为我们总是遍历整个桶页并查找数据，而不是根据哈希函数得到最佳位置，再往后遍历，故不存在遇到空位停止查找的问题

### 成员函数设计

#### Hash Table Bucket Page

- `bool GetValue(key, cmp, result)`

  遍历桶中每个数据项，若其键值与目标键值相同，则将其加入结果数组中

  ```c++
  template <typename KeyType, typename ValueType, typename KeyComparator>
  bool HASH_TABLE_BUCKET_TYPE::GetValue(KeyType key, KeyComparator cmp, std::vector<ValueType> *result) {
    bool found = false;
    for (size_t i = 0; i < BUCKET_ARRAY_SIZE; ++i) {
      if (IsReadable(i) && cmp(key, KeyAt(i)) == 0) {
        result->push_back(ValueAt(i));
        found = true;
      }
    }
    return found;
  }
  ```

- `bool Insert(key, value, cmp)`

  - 找重复：遍历桶中各个槽，如果找到一个槽其键值与要插入的键值完全一致，则返回false
  - 找空位：将第一个空的槽的位置记录下来，找不到空位也返回false
  - 插入：若没有重复且有空位，则将数据插入第一个空位，设置相应的`readable_`标志、`occupied_`标志，并将键值对存入`array_`

  ```c++
  template <typename KeyType, typename ValueType, typename KeyComparator>
  bool HASH_TABLE_BUCKET_TYPE::Insert(KeyType key, ValueType value, KeyComparator cmp) {
    size_t index = 0;
    bool found = false;
    for (size_t i = 0; i < BUCKET_ARRAY_SIZE; ++i) {
      if (!IsReadable(i)) {
        if (!found) {
          found = true;
          index = i;
        }
      } else {
        if (cmp(array_[i].first, key) == 0 && array_[i].second == value) {
          return false;
        }
      }
    }
    if (found) {
      SetOccupied(index);
      SetReadable(index);
      array_[index] = std::make_pair(key, value);
      return true;
    }
    return false;
  }
  ```

- `bool Remove(key, value, cmp)`

  遍历桶中每个项，若找到键值对相符的数据，则将其移除，将其`readable_`设为不可读

  ```c++
  template <typename KeyType, typename ValueType, typename KeyComparator>
  bool HASH_TABLE_BUCKET_TYPE::Remove(KeyType key, ValueType value, KeyComparator cmp) {
    for (size_t i = 0; i < BUCKET_ARRAY_SIZE; ++i) {
      if (IsReadable(i) && cmp(array_[i].first, key) == 0 && array_[i].second == value) {
        readable_[i / SIZE_CHAR] &= 0xff ^ (1 << (i % SIZE_CHAR));
        return true;
      }
    }
    return false;
  }
  ```

- `bool IsOccupied(bucket_idx)`

  返回该位置是否被占据

  ```c++
  template <typename KeyType, typename ValueType, typename KeyComparator>
  bool HASH_TABLE_BUCKET_TYPE::IsOccupied(uint32_t bucket_idx) const {
    return (occupied_[bucket_idx / SIZE_CHAR] & (1 << (bucket_idx % SIZE_CHAR))) != 0;
  }
  ```

- `bool IsReadable(bucket_idx)`

  返回该位置是否可读

  ```c++
  template <typename KeyType, typename ValueType, typename KeyComparator>
  bool HASH_TABLE_BUCKET_TYPE::IsReadable(uint32_t bucket_idx) const {
    return (readable_[bucket_idx / SIZE_CHAR] & (1 << (bucket_idx % SIZE_CHAR))) != 0;
  }
  ```

- `keyType KeyAt(bucket_index)`

  返回该位置存储的**数据项的键**

  ```c++
  template <typename KeyType, typename ValueType, typename KeyComparator>
  KeyType HASH_TABLE_BUCKET_TYPE::KeyAt(uint32_t bucket_idx) const {
    return array_[bucket_idx].first;
  }
  ```

- `ValueType ValueAt(bucket_index)`

  返回该位置存储的**数据项的值**

  ```c++
  template <typename KeyType, typename ValueType, typename KeyComparator>
  ValueType HASH_TABLE_BUCKET_TYPE::ValueAt(uint32_t bucket_idx) const {
    return array_[bucket_idx].second;
  }
  ```

#### Hash Table Directory Page

- `page_id_t GetBucketPageId(bucket_idx)`

  获取第bucket_idx个桶对应的页号

  ```c++
  page_id_t HashTableDirectoryPage::GetBucketPageId(uint32_t bucket_idx) { return bucket_page_ids_[bucket_idx]; }
  ```

- `void SetBucketPageId(bucket_idx, bucket_page_id)`

  设置第bucket_idx个桶对应的页号

  ```c++
  void HashTableDirectoryPage::SetBucketPageId(uint32_t bucket_idx, page_id_t bucket_page_id) {
    bucket_page_ids_[bucket_idx] = bucket_page_id;
  }
  ```

  

## Task2 Hash Table Implemention

### 功能需求

- **目录索引**

  将数据插入哈希表时，采用低有效位进行索引

- **桶分裂**

  当插入会引起桶溢出时，进行分裂

- **桶合并**

  - 桶变为空时，尝试进行合并
  - 只有当桶和其split image拥有相同的局部深度时，才能合并
  - 只有当桶的局部深度大于0时，才能合并

- **目录增长**

  当某个桶的局部深度超过了全局深度时，将全局深度加1，并进行目录增长

- **目录收缩**

  当每个桶的局部深度都严格小于全局深度时，进行目收缩

### 辅助函数

- `Hash(key)`，计算key的哈希值
- `KeyToDirectoryIndex`，返回key对应的目录页索引（代表**将key映射到第index个桶**），其计算公式为
  - **DirectoryIndex = Hash(key) & GLOBAL_DEPTH_MASK**
  - GLOBAL_DEPTH_MASK是根据现有全局深度生成的位掩码，若当前全局深度为$i$，若数与该位掩码相与，则代表取该数最低的$i$位
- `KeyToPageId`，返回key对应的bucket page的页号
  - 首先获取该key的目录页索引bucket_index，即该key将**被映射到第`bucket_index`个桶**
  - 然后根据目录页的页表，**查找第`bucket_index`个桶对应的页号**
- `FetchDirectoryPage()`，**获取目录页**
- `FetchBucketPage(bucket_page_id)`，根据页号**获取该桶页**
- `UnpinDirectoryPage()`，**释放目录页**
- `UnpinBuceketPage(bucket_page_id)`，**释放桶页**

### 成员函数设计

#### 查找

- `bool GetValue(transaction, key, result)`，实现**查找**功能

  - 获取哈希表的S锁

  - 获取目录页`dir_page`，在目录页中查找`key`对应的`bucket_page_id`，并获取该桶页`bucket_page`
  - 获取该桶页的S锁
  - 调用该桶页的`GetValue`方法查找该键对应的值
  - 调用`UnpinBucketPage`释放该桶页
  - 调用`UnpinDirectoryPage`释放目录页
  - 释放该桶页、目录页的S锁

#### 插入 + 桶分裂

- `bool Insert(transaction, key, value)`，实现**插入功能**

  - **直接插入**：获取该键对应的bucket page，若未满，则直接插入并返回

  - **桶分裂**：若该bucket page满了，则需要进行桶分裂

  - **桶A的局部深度$i_A$小于全局深度$i$**：因此桶地址表中不止一个表项指向桶A，系统不需要增加桶地址表的规模也能进行分裂

    - **分裂**：分配新的桶A' (split image)，将其桶A和A'的局部深度$i_A$和$i_{A'}$设置为原$i_A$加1
    - **调整桶地址表**：对于桶地址表指向A的所有项，若其新增加的位为0则指向桶A，若其新增加的位为1则指向桶A'
    - **重新散列数据**：对于存储在桶A中的数据项，重新将其散列，要么插入桶A，要么插入桶A'

  - **桶A的局部深度$i_A$等于全局深度$i$**：因此桶地址表中只有1个表项指向桶A，系统需要将桶地址表的规模加倍

    - **桶地址表规模加倍**：全局深度加1，因此表项数量变为原来的两倍
    - **调整桶地址表（其他）**：每个旧表项都生成了两个新表项，这两个新表项应指向旧表项所指向的桶，同时其局部深度也等于旧表项的局部深度

    - **分裂**：分配新的桶A' (split image)，将桶A和A'的局部深度$i_A$和$i_{A'}$设置为原$i_A$加1
    - **调整桶地址表（桶A）**：特别地，原来指向桶A的表项生成了两个新表项，它们其中一个指向桶A，另一个则指向新分配的桶A'，且两个新表现的局部深度都应该等于原$i_A$加1
    - **重新散列数据**：对于存储在桶A中的数据项，重新将其散列，要么插入桶A，要么插入桶A'

  - 进行桶分裂之后，再次尝试插入表项，若成功则返回，否则**循环分裂直至插入成功**

#### 删除 + 桶合并

- `bool Remove(transaction, key, value)`
  - **删除数据项**：获取该键对应的桶A，并删除该数据项
  - **检查桶合并条件**：若该桶A变为空，且局部深度大于0，则查找其split image桶A'，若桶A'与桶A的局部深度相等，则进行桶合并
  - **桶合并**：遍历桶地址表的表项，若表项指向A则修改其指向桶A'，并将其局部深度减1；若表项指向A'则将其局部深度减1
  - **删除桶**：调用`DeletePage`删除桶A的页
  - **桶地址表规模减半**：如果当前所有桶的局部深度都小于全局深度，则全局深度减1（循环的最终结果是，**全局深度**会等于所有桶的**局部深度的最大值**）
  - **再次检查桶合并**：遍历桶地址表中的每个表项，若其指向的桶为空，且局部深度非0，且split image的局部深度与其相等，则进行同合并

## Task3 Concurrency Control

### 功能需求

- 进行查找、插入、删除时**正确地获取和释放锁**
- 尽可能地只在需要的时候持有锁，以提高**并发度**

### 关键问题分析

- **查找**需要获取什么锁？

  **整个表的S锁**，该键所在的**桶的S锁**

- **插入**需要获取什么锁？

  - 如果只是进行**插入**操作，只需获取**整个表的S锁**、该键所在的**桶的X锁**
  - 如果进行**分裂**，因为要修改桶地址表，需要且只需要获取**整个表的X锁**

- **删除**需要获取什么锁？

  - 如果只是进行**删除**操作，只需获取**整个表的S锁**，该键所在的**桶的X锁**
  - 如果进行**合并**，因为要修改桶地址表，需要且只需要获取**整个表的X锁**

# Project 3 Query Execution

## 回顾：查询处理

### 1 查询执行计划

- DBMS将SQL语句转化为一个**查询执行计划**（query plan），查询计划中的运算符以**树**的形式进行组织
- 数据从树的叶子流向树根，根节点的输出就是查询的结果
- 典型的运算符是二元的，因此拥有1或2个子节点
- 同一个查询计划可以以不同的方式执行

### 2 处理模型

- DBMS**处理模型**定义了系统**如何执行查询计划**，它定义了
  - 查询计划求值的方向
  - 运算符之间传递的数据
- 常用的三种处理模型
  - **迭代器模型**
  - Materialization模型
  - Vectorized/Batch模型

#### 迭代器模型（Volcano模型）

- 每个运算符都有一个**Next函数**
- 查询计划中的每个节点都不断地对其**子节点调用Next函数**，直至到达叶节点，然后将元组传递给其父节点进行处理
- Next函数
  - Next函数要么**返回一个元组**，要么返回一个**标记指明没有更多的元组**
  - 运算符使用**while循环**对其子节点调用Next，每次调用获取一个元组，并处理它，直至**所有元组都处理完**
- **管道**技术
  - DBMS可以将一个元组尽可能在更多的运算符之前传递，而无需等待下一个元组到来
  - 某些运算符需要获取所有元组后才可以处理，如join、子查询、排序等，它们被称为pipeline breakers
  - 通过pipeline breakers可以实现**输出控制**

## 整体功能需求

- 实现**executors**，负责执行相应的查询plan nodes，需要支持的操作包括
  - 读取：Sequential Scan
  - 修改：Insert、Update、Delete
  - 其他：Nexted Loop Join、Hash Join、Aggregation、Limit、Distinct
- 处理模型使用迭代器模型，也称为**Volcano模型**
  - 每个查询的executor都包含一个Next函数，调用该函数将会返回一个元组，或一个表示已经没有元组的标记，因此executor可以通过循环地调用Next函数来获取元组并处理它们
  - Next函数返回的是元组的RID，能够唯一地标识一个元组

## Task1 Executors

### 功能需求

- **实现Executor类**：提供以实现的Query plan类，需要实现Executor类，调用Next函数从子节点获取元组，完成处理，并向父节点传递元组
- **运算类型**：需要支持的运算包括Sequential scan、Insert、Update、Delete、Nested Loop Join、Hash Join、Aggregation、Limit、Distinct，共九种运算

### 辅助类及其关键接口

#### Value

- 用于表示**各种类型的值**，根据值的类型提供了不同的比较运算、算术运算等操作

#### Tuple

- 元组，可理解为数据库中的一行，`data_`字段存储了Value

- `Value GetValue(const Schema*, const int32_t column_idx)`

  **获取**该元组**指定列的值**

#### Table Page

- 继承于Page类，是表的存储单元，一个表可由多个table pages组成
- 提供了Tuple的页操作，如`InsertTuple`、`MarkDelete`、`UpdateTuple`等

#### Table Heap

- 代表磁盘上的一张物理表，使用**双向链表存储多个table pages**
- 提供了将Tuple的表操作，如`InsertTuple`、`MarkDelete`、`UpdateTuple`等，它们将调用该元组所在的Table Page的对应方法

#### Table Iterator

- 表项的**迭代器**，**指向表中的某个tuple**
- 支持迭代器的**解引用、箭头运算符、递增运算符**（包括前置、后置版本）等操作

#### RID

- 记录一个**tuple的地址**，包括**其所在页的页号page id**和**页中槽位slot number**

#### Column

- 表中某一列的列头信息，包括名字、类型等

#### Schema

- 记录表的所有列头信息，维护一个columns数组
- 提供接口
  - `Column GetColumn(uint32_t) i`，获取第$i$列
  - `uint32_t GetColIdx(const string &col_name)`，查找该列名对应列的列号

#### Index

- 表格的索引信息，每个索引提供tuple到RID的对应关系

#### Catalog

- 一个数据库的全部表格信息的索引，提供了对表格的操作。成员变量主要包括：TableInfo的表，每个TableInfo包括一个表格的ID、Schema、TableHeap；IndexInfo的表，即每个表格的索引信息

### SEQUENTIAL SCAN

- **Init函数功能**：将迭代器设置为表的开始位置，从第一个tuple开始扫描

- **Next函数功能**：找到一个符合谓词判断的tuple，并返回true，若找不到则返回false

- **扫描**：通过**Table Iterator迭代器**不断获取当前Table的tuple
- **谓词判断**：利用`plan_->GetPredicate()`对tuple进行判断，若为真则将该tuple赋给指针并返回true，若为假则继续寻找下一个tuple
- **返回**：若直到结尾也没找到符合predicate的tuple，则返回false

```c++
void SeqScanExecutor::Init() { iter_ = table_info_->table_->Begin(txn_); }

bool SeqScanExecutor::Next(Tuple *tuple, RID *rid) {
  // predicate can be nullptr, which means every tuple statisfy the predicate
  while (iter_ != table_info_->table_->End()) {
    if (plan_->GetPredicate() == nullptr ||
        plan_->GetPredicate()->Evaluate(&(*iter_), plan_->OutputSchema()).GetAs<bool>()) {
      // re-construct the tuple using output schema
      std::vector<Value> data;
      for (const auto &c : plan_->OutputSchema()->GetColumns()) {
        data.push_back(iter_->GetValue(&table_info_->schema_,
                                       dynamic_cast<const ColumnValueExpression *>(c.GetExpr())->GetColIdx()));
      }
      *tuple = Tuple(data, plan_->OutputSchema());
      *rid = iter_->GetRid();
      ++iter_;
      return true;
    }
    ++iter_;
  }
  return false;
}
```

### INSERT

- 支持两种插入操作
  - raw insert：将要插入的值存放在plan node
  - child insert：从child executor获取值后插入
- 插入一个tuple
- 更新索引
- 返回该tuple及其RID

### UPDATE

### DELETE

### NESTED LOOP JOIN

### HASH JOIN

### AGGREGATION



### LIMIT

- **Init函数功能**：将迭代器设置为表的开始位置，从第一个tuple开始扫描；并将计数值设为0
- **Next函数功能**：获取下一个tuple，若到达表的末尾，或已获取的tuple数量到达limit值，则返回false
- **扫描**：通过`child_executor_->Next(tuple, rid)`获取下一个tuple，并更新计数值

```c++
void LimitExecutor::Init() {
  child_executor_->Init();
  cnt_ = 0;
}

bool LimitExecutor::Next(Tuple *tuple, RID *rid) {
  if (!child_executor_->Next(tuple, rid)) {
    return false;
  }
  cnt_++;
  return cnt_ <= plan_->GetLimit();
}
```

### DISTINCT

- 

# Project 4 并发控制

## 整体功能需求

- 实现一个**锁管理器**，使得数据库系统支持**并发查询执行**
- 锁管理器需要**跟踪授予事务的tuple-level锁**
- 锁管理器需要根据事务的**隔离水平**进行**S锁和X锁的授予、释放**
- 基于**Wound-Wait算法**实现**死锁预防**机制
- 修改Insert、Seq_scan、Delete、Update **Execurtor**，使其正确地向锁管理器**请求获取和释放锁** 

## Task1 实现锁管理器

### 功能需求

- 锁管理器维护一个**锁表**，通过数据结构存储当前哪些事务获取了哪些锁
- 锁管理器**接受**事务发出的**加锁请求**，锁管理器判断其是否可以获取锁，最终执行以下三种操作中的一种
  - 将锁**授予**该事务
  - **阻塞**该事务
  - **中止**该事务
- 整个数据系统锁管理器维护一个全局的锁表 ，当事务需要访问或修改一个tuple时，相应的Executor需要向锁管理器发送某个`RID`的锁请求。锁管理器根据事务的隔离水平，决定授予或释放锁
  - 可重复读，遵循两阶段封锁协议（2PL），Growing阶段可以获取或升级锁，Shrinking阶段可以释放或降级锁
  - 已提交读，S-lock可以在读取后立即释放，X-lock遵循2PL
  - 未提交读，X-lock可以在修改后立即释放，无需获取S-lock（因此可读取到未提交的数据）
- 锁管理器需要实现基于Wound-Wait的死锁预防策略，具体地
  - **伤害-等待机制**是**抢占**式的，若$T_i$申请的数据项被$T_j$持有时，仅当$T_i$比$T_j$更年轻时才等待，否则**$T_j$回滚（$T_j$被$T_i$伤害）**

### 关键问题分析

- WOUND-WAIT算法中，如何判断两个事务younger？

  根据时间戳，在本实验的接口设计中，事务开始前分配的**transaction id就是其时间戳**，该值由transaction manager管理，每个事务start后递增

- WOUND-WAIT算法中，遇到更年轻的事务持有锁应该将其中止，若队列中遇到更年轻的事务，但其未获取锁（等待中），是否应该将其中止？

  应该

- 各个**隔离等级**的区别是什么？

  - 可重复读：遵循2PL
  - 已提交读：只允许读取已提交的数据，S锁读取后立即释放，X锁遵循2PL
  - 未提交读：允许读取未提交的数据（无需获取S锁），X锁读取后立即释放
  
- WOUND-WAIT算法中如何**中止其他事务**？

  通过SetState将其**状态设为Aborted**（实验文档要求抛出异常，事务管理器的异常处理代码会调用Abort中止相应事务，但实际上测试程序并没有异常处理代码）

- WOUND-WAIT算法中，如果事务$T_i$中止了事务$T_j$后，队列前方没有其他事务请求获取该锁，则事务$T_i$应该继续等待直至事务管理器Abort事务$T_j$时执行Unlock释放该锁，还是可以立即获取该锁？

  中止了该事务就可以认为该事务释放了所持有的锁，$T_i$可以立即获取该锁（需要满足FCFS，队列中没有更早的事务请求获取该锁）

  > 此问题是在测试程序debug中发现的，并不易想到，而且有点反正常逻辑

- 假如被中止的事务处于阻塞状态，则它无法发现自己被阻塞了，如何处理该问题？

  在中止事务时，通过其`GetSharedLockSet()`和`GetExclusiveLockSet()`接口获取其拥有的每个锁，并调用相应的请求队列的条件变量的`notify_all()`函数**唤醒阻塞的进程**

- 事务请求队列包含一个`upgrading_`数据成员，记录当前正在升级（如有）的事务id，其作用是什么？

  - 对于同一个数据项，**一次只允许一个事务升级**，事务升级前必须通过将upgrading_置为自己的事务id获得该权限，如果当前upgrading存储了其他事务的id，则必须阻塞
  - 一次只允许一个事务升级的原因是，假如该数据项的请求队列中只包含事务$T_i$和事务$T_j$,它们都获取了S锁，若允许两个事务升级，则它们都在**等待对方解S锁**，从而导致死锁

  > 事实上，由于引入了死锁预防机制，WOUND-WAIT算法保证了即使两个事务同时升级锁，必定有一个会将另一个中止，因此无需该upgrading_变量了

### 数据结构与算法设计

- 锁表设计
  - 锁表是一个**散列表**，以数据项的RID作为关键字进行散列
  - 锁表的每个表项是一个**请求队列**`LockRequestQueue`，代表请求获取该表项的锁的事务请求队列，包含
    - 该队列本质上是一个**链表**，由`std::list`实现的`request_queue_`表示
    - 用于阻塞和唤醒事务的**条件变量**`cv_`
    - 当前正在**进行升级的事务id**`upgrading_`
  - 请求队列中的每个节点代表请求获取该锁的一个事务`LockRequest`，其中存储了
    - 该**事务id**`txn_id_`
    - 请求的**锁模式**`lock_mode_`
    - **是否授予**`granted_`

### 成员函数设计

#### 辅助成员

- `bool CheckAbort(Transaction *txn)`

  在事务获取/升级锁之前调用，检查事务是否处于`GROWING`状态，若否则**中止**事务

- `bool SetAbort(Transaction *txn, AbortReason reason)`

  将该事务的状态设置为Aborted，（同时抛出异常`TransactionAbortException`，包含中止原因`reason`）

  > 注：括号中为实验文档表述，但实际上gradescope的测试程序并没有异常处理的代码，因此不能抛出异常

以下`CheckXXXWait`函数的作用，均为**扫描队列**检查能否获取锁，若返回true意味着我们**需要等待**，返回false意味着我们**无需等待**。该过程中可能通过wound-wait算法**中止其他事务**。

- `bool CheckSharedWait(Transaction *txn, std::list<LockRequest>* q)`

  扫描该表项的请求队列，判断事务**能否获取共享锁**，若不能则事务继续等待

  - 初始化等待标志`flag`为false

  - 如果遇到**older（时间戳更小）的事务**，如果其为S锁则`flag`不变，如果其为**X锁**则将标志`flag`置为true，意味需要**等待**
  - 如果遇到**younger的事务**，如果其为S锁则`flag`不变，如果其为**X锁**则直接将该事务**中止**，此时`flag`**不变**，意味着我们将其状态设为中止后**可以立即获取该锁**（只要没遇到上述的older事务），而**无需等待**事务管理器真正执行Aborted将其中止
  - 如果遇到了事务本身的请求，则可以停止扫描并返回`flag`，因为根据FCFS保证我们无需考虑后面的事务

- `bool CheckExclusiveWait(Transaction *txn, std::list<LockRequest>* q)`

  扫描该表项的请求队列，判断事务**能否获取排他锁**，若不能则事务继续等待

  - 基本原理同上，唯一的区别是**X锁与S锁、X锁都不相容**
  - 初始化等待标志`flag`为false
  - 如果遇到older（时间戳更小）的事务，**无论是X锁还是S锁**，都将标志`flag`置为true，意味需要等待
  - 如果遇到younger的事务则将该事务**中止**，此时`flag`不变，意味着我们将其状态设为中止后可以立即获取该锁（只要没遇到上述的older事务），而无需等待事务管理器真正执行Aborted将其中止
  - 如果遇到了事务本身的请求，则可以停止扫描并返回`flag`，因为根据FCFS保证我们无需考虑后面的事务

- `bool CheckUpgradeWait(Transaction *txn, std::list<LockRequest>* q)`

  扫描该表项的请求队列，判断事务**能否升级锁**，若不能则事务继续等待

  - 仅当**队列前方只有该事务的S锁请求**时，才能升级锁
  - 初始化等待标志`flag`为false
  - 如果遇到older（时间戳更小）的事务，**无论是X锁还是S锁**，都将标志`flag`置为true，意味需要等待
  - 如果遇到younger的事务则将该事务**中止**，此时`flag`不变，意味着我们将其状态设为中止后可以立即获取该锁（只要没遇到上述的older事务），而无需等待事务管理器真正执行Aborted将其中止
  - 如果遇到了事务本身的请求，若为S锁则继续遍历，若为X锁则可以停止扫描并返回`flag`

#### 公共接口

- `bool LockShared(Transaction *txn, const RID &rid)`，事务**请求获取S锁**的接口
  - 获取**锁表的互斥锁**，不同事务对锁表的访问是互斥的
  - 如果该事务**处于`Shrinking`或`Aborted`状态**，则无法获取锁，**返回false**
  - 如果该事务已经**拥有了同一数据项的X锁**，则**返回false**
  - 如果该事务的隔离水平是**未提交读**，则它无需获取S锁，**将该事务中止，并返回false**
  - 如果该事务已经**拥有了同一数据项的S锁**，则**返回true**
  - 否则，将该事务的请求**加入**锁表中对应项的**链表**中，同时**更新事务的**`SharedLockSet`
  - 运行`CheckSharedWait`辅助函数查看**是否需要等待**，若需要等待则**阻塞**；若不需要等待则直接**获取锁并返回true**
  - 当被阻塞的事务**被唤醒**时
    - 先**检查自己的状态是否为`ABORTED`**（因为死锁预防机制使得事务可以中止其他事务，而被中止的事务可能位于阻塞状态，因此被唤醒后应该先检查自己是否处于中止状态），若位于中止状态则返回false
    - 若仍处于活跃状态则**再次运行**`CheckSharedWait`辅助函数查看是否需要等待（**防止虚假唤醒**）
- `bool LockExclusive(Transaction *txn, const RID &rid)`，事务**请求获取X锁**的接口
  - 获取**锁表的互斥锁**，不同事务对锁表的访问是互斥的
  - 如果该事务**处于`Shrinking`或`Aborted`状态**，则无法获取锁，**返回false**
  - 如果该事务已经**拥有了同一数据项的S锁**，则它应该通过Upgrade升级锁，**返回false**
  - 如果该事务已经**拥有了同一数据项的X锁**，则**返回true**
  - 否则，将该事务的请求**加入**锁表中对应项的**链表**中，同时**更新事务的**`ExclusiveLockSet`
  - 运行`CheckExclusiveWait`辅助函数查看**是否需要等待**，若需要等待则**阻塞**；若不需要等待则直接**获取锁并返回true**
  - 当被阻塞的事务**被唤醒**时
    - 先**检查自己的状态是否为`ABORTED`**（因为死锁预防机制使得事务可以中止其他事务，而被中止的事务可能位于阻塞状态，因此被唤醒后应该先检查自己是否处于中止状态），若位于中止状态则返回false
    - 若仍处于活跃状态则**再次运行**`CheckExclusiveWait`辅助函数查看是否需要等待（**防止虚假唤醒**）
- `bool LockUpgrade(Transaction *txn, const RID &rid)`，事务**请求升级锁**的接口
  - 获取**锁表的互斥锁**，不同事务对锁表的访问是互斥的
  - 如果该事务**处于`Shrinking`或`Aborted`状态**，则无法获取锁，**返回false**
  - 如果该事务并**不拥有同一数据项的S锁**，则**返回false**
  - 如果该事务已经**拥有了同一数据项的X锁**，则**返回true**
  - 否则，将该事务的请求**加入**锁表中对应项的**链表**中，同时**更新事务的**`ExclusiveLockSet`
  - 运行`CheckExclusiveWait`辅助函数查看**是否需要等待**，若需要等待则**阻塞**；若不需要等待则**升级锁，从等待队列中移除先前的S锁请求，并返回true**
  - 当被阻塞的事务**被唤醒**时
    - 先**检查自己的状态是否为`ABORTED`**（因为死锁预防机制使得事务可以中止其他事务，而被中止的事务可能位于阻塞状态，因此被唤醒后应该先检查自己是否处于中止状态），若位于中止状态则返回false
    - 若仍处于活跃状态则**再次运行**`CheckExclusiveWait`辅助函数查看是否需要等待（**防止虚假唤醒**）
- `bool Unlock(Transaction *txn, const RID &rid)`，事务**解锁**的接口
  - 检查该事务的`SharedLockedSet`和`ExclusiveLockedSet`，如果不包含`rid`则直接返回false
  - 获取**锁表的互斥锁**，不同事务对锁表的访问是互斥的
  - 扫描该数据项的请求队列，如果遇到该事务的请求，则将其移除，同时将`rid`从该事务的`SharedLockedSet`或`ExclusiveLockedSet`移除
  - 如果该事务**隔离水平为可重复读**，则它需要**遵循2PL**，因此如果其状态为`GROWING`，则将其**设为`SHRINKING`**
  - 由于进行了解锁，因此调用该数据项请求队列的条件变量的`notify_all()`，**唤醒阻塞在该队列的其他事务**

### 实现

### Debug过程

- **问题1**：将WOUND-WAIT算法中的younger与older搞反了

- **问题2**：获取锁请求等待队列时，使用了`auto q = ...`，从而得到了该队列的拷贝，所有操作都无法反映在系统的请求等待队列中，应修改为`auto &q = ...`

- **问题3**：使用for循环在遍历list的过程中删除元素。解决：利用`erase`返回的指向被删除元素后一位置的迭代器，使用while循环遍历list

- **问题4**：ABORT时throw exception

  讲义要求中止事务时先修改其状态为`ABORTED`，然后抛出异常让事务管理器类中止该事务。但实际上测试代码中并没有catch该异常的代码， 因此**不能主动抛出异常**

- **问题5**：提示超时

  修改1：修改获取锁的程序，如果它已持有该锁应该return true

  修改2：对于已提交读，获取S锁并读取后应该立即释放

  修改3：对于已提交读和未提交读，获取X锁并写入后应该立即释放，**只有可重复读需要遵循2PL**

  修改4：在UPGRADE中，应该首先检查`upgrading_`是否为INVALID_TXN_ID，若是则将其设为事务id，否则等待。**将`upgrading_`设为事务id后，才可以将UPGRADE请求加入队列**

  修改5：在将事务的锁请求加入等待队列的同时，将该锁加入其write或read锁集合中

  修改6：如果将进程设为ABORT了之后，应该在对应的RID的等待队列执行一次条件变量的`notify_all()`

  **修改7：只要通过WOUND-WAIT算法将其他事务中止（将其state设为Aborted），无需等待事务管理器执行ABORT时执行Unlock，直接就可以释放其上的锁**

  - 比如，时间戳为2的事务A获取了数据项Q的S-lock，此后时间戳为1的事务B请求获取数据项Q的X-lock，此时根据WOUND-WAIT算法事务B将事务A中止。此时即使事务A阻塞而无法检测到自己状态变为Aborted，事务B也可以直接获取X-lock

## Task2 修改Executor

### Debug过程

- 问题1：Rollback问题

  修改：应该在INSERT、DELETE、UPDATE时，将索引的改变写入日志，具体地，对于每个索引变化都要事务的`AppendTableWriteRecord`方法添加一条日志记录，如下所示

  ```c++
  txn_->AppendTableWriteRecord(IndexWriteRecord(r, info->oid_, WType::INSERT, key, index_info->index_oid_, catalog_));
  ```

### 关键问题分析

- 不同隔离水平的读写操作的区别

  - **可重复读**，seq_scan获取S锁，insert、delete、update获取X锁，且要**遵循2PL**，**读写后不能立即释放锁**，而是由事务管理器释放其持有的锁
  - **已提交读**，seq_scan获取S锁，读完**立即释放S锁**；insert、delete、update获取X锁，**X锁遵循2PL**，不要立即释放，由事务管理器释放其持有的X锁
  - **未提交读**，seq_scan**无需获取S锁**，insert、delete、update获取X锁，**写完可以立即释放X锁**

- 对**索引的修改**需要**写日志记录**

  - 应该在INSERT、DELETE、UPDATE时，将索引的改变写入日志，具体地，对于每个索引变化都要事务的`AppendTableWriteRecord`方法添加一条日志记录，如下所示
  - 该日志记录包含数据项的`rid`、表的`oid`、写类型（INSERT、DELETE或UPDATE）、tuple项、索引的`oid`、文件目录`catalog_`

  ```c++
  txn_->AppendTableWriteRecord(IndexWriteRecord(r, info->oid_, WType::INSERT, key, index_info->index_oid_, catalog_));
  ```

​	
