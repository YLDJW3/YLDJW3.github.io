---
title: 图解系统笔记
date: 2022-03-29 11:55:08
tags: 
    - OS
    - 面试
categories: Computer Network
mathjax: true
---

# 硬件结构

## 冯诺依曼模型

- **计算机结构**：中央处理器、内存、输入设备、输出设备、总线

## 程序执行的基本过程

- **取指**：CPU读取PC得到指令的内存地址，访问该内存得到指令并存入指令寄存器
- **执行**：分析指令寄存器中的指令，若为计算类型的指令则交给逻辑运算单元运算，若为存储类型的指令则交给控制单元执行
- **PC自增**：指令执行完后，PC自增指向下一条指令

## 指令周期

- **Fetch**：取得指令
- **Decode**：指令译码
- **Execution**：执行指令
- **Store**：数据回写

## 存储器金字塔

- **寄存器**：读写速度最快
- **CPU cache**：读写速度快，存储容量小，静态随机存储器SRAM，分为三级L1、L2、L3 Cache
- **内存**：动态随机存储器DRAM
- **SSD/HDD硬盘**：存储容量大，读写速度慢，断电后数据仍存在

## CPU缓存一致性

- 多核CPU中，每个核心都有**各自的L1/L2 Cache**，而**L3 Cache**则是所有核心**共享**使用的

### 写直达

- **写直达**：把数据同时写入内存和Cache中
- **如果数据没有在Cache里面**：直接把数据更新到内存中
- **缺点**：每次写操作都写回到内存，写操作花费大量时间

### 写回

- **写回**：发生写操作时，新的数据仅仅写入Cache block，只有当修改过的Cache block被替换时，才需要写到内存中

- **写操作时数据已经在CPU Cache中**：数据更新到CPU Cache里，标记CPU Cache里的block为dirty，代表该block的数据和内存是不一致的
- **写操作时数据不在Cache中**：进行替换，检查被替换的Cache block是否为dirty，若为dirty则要把Cache Block里的数据写回到内存，在把当前要写入的数据写入到Cache block并标记为dirty

- **优点**：减少了写内存的次数，性能提高

# 操作系统结构

- **操作系统的作用**：进程管理、内存管理、设备管理、提供系统调用

## 内核态与用户态

- **内核态与用户态**：内核程序执行在内核态，用户程序执行在用户态

- 内核态与用户态的切换方式

  **系统调用**：用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作

  **异常**：CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中

  **设备中断**：外围设备完成用户请求的操作后，向CPU发出中断信号

- **系统调用**：应用程序使用系统调用时会产生一个**中断**。发生中断后，CPU会中断当前在执行的用户程序，转而跳转到**中断处理程序**，即开始执行内核程序。内核处理完成后，主动触发**中断**，把CPU执行权限交回给**用户程序**，回到用户态继续工作

## 宏内核与微内核

- **宏内核**：系统内核的所有模块都运行在内核态
- **微内核**：内核只保留最基本的能力，如进程调度、虚拟机内存、中断等
- **混合类型内核**：内核里有一个最小版本的内核，其他模块在其基础上搭建，但整个内核是仍然作为一个完整程序，大部分服务都在内核中

# 内存管理

## 虚拟内存的概念

- **虚拟内存**：操作系统让每个进程都拥有独立的连续地址空间，称为虚拟内存
- **虚拟内存地址与物理内存地址**：进程使用虚拟内存地址访问内存，而存在硬件中的实际地址是物理内存地址，虚拟内存地址到物理地址的转换是由硬件**内存管理单元MMU**完成的

- **分段/分页**：内存空间常通过分段或分页的方式进行组织

## 内存分段

- **分段**：程序由若干个逻辑分段组成，如代码分段、数据分段、栈段、堆段，不同的段有不同的属性

- **虚拟地址**：由段号和段内偏移量组成

- **段表**：虚拟地址通过段表与物理地址进行映射，段表中包含段基地址、段界限

- 虚拟地址向物理地址转换的过程

  **根据段号索引段表**：根据虚拟地址的段号找到段表

  **检查越界**：对比段内偏移量和段表中的段界限，判断虚拟地址是否合法

  **得到物理地址**：段基地址加上段内偏移量即得到虚拟地址对应的物理地址

- 缺点

  **内存碎片**：产生多个不连续的小物理内存，导致新的程序无法被装载

  **内存交换效率低**：为了解决内存碎片问题，采用内存交换方法，先将程序写到硬盘上，再从硬盘读回内存，并紧跟着上一个程序，从而消除了该内存碎片。如果将较大的程序写回硬盘再读入内存，则速度较慢

## 内存分页

- **分页**：把整个虚拟和物理内存空间切成一段段固定尺寸的大小，这个连续且尺寸固定的内存空间称为**页**
- **页表**：虚拟地址与物理地址之间通过页表进行映射，内存管理单元MMU负责将虚拟地址映射为物理地址
- **缺页异常**：当进程访问的虚拟地址在页表中查不到时，产生一个缺页异常，进入内核态由操作系统分配物理内存、更新进程页表，最后返回用户空间继续执行

### 分页怎么解决内存碎片、内存交换效率低等问题

- **内存碎片问题**：采用分页，内存的释放是以页为单位进行的，不会产生无法给进程使用的小内存
- **内存交换效率问题**：**LRU策略**，当内存空间不足时，若需要换入新页面，则操作系统将最久未被使用的内存页面释放掉

- **Demand paging**：加载程序时，无需把整个程序加载到物理内存中，而是在进程使用该页时，发生缺页异常时由操作系统将该页换入内存中

### 虚拟地址和物理地址的映射

- **虚拟地址**：分为页号和页内偏移量

- **页表**：包含物理页所在的物理内存基地址，由该基地址和页内偏移量组合得到虚拟地址对应的物理地址

- **地址转换**的步骤

  虚拟地址划分为**页号**和**偏移量**

  根据页号从页表里查询得到物理页所在内存的**物理内存基地址**

  将物理页基地址加上**页内偏移量**得到**物理内存地址**

- **分页的缺点**

  **页表占用较大存储空间**：若页的大小为4KB，而虚拟地址空间为4GB，则共有$2^{20}$个页，每个页表项为4字节，则共需要4MB空间存放页表

### 多级页表

- **目的**：解决页表占用过多存储空间的问题
- **原理**：将上述$2^{20}$个页建立两级页表，一级页表包含1024个页表项，对应1024个二级页表；二级页表也包含1024个页表项，对应$2^{20}$个物理页
- **优点**：进程并非需要页表中的每一项，因此部分页表项是空的，即一级页表中的部分表项不需要建立对应的二级页表。具体地，考虑一个进程只使用了4MB的连续空间，则只需要一个一级页表和一个二级页表即可，总共$2*2^{10}$个页表项。若不采用多级页表，则他仍然需要为每个页建立一个页表项，共$2^{20}$个页表项
- **速记**：一级页表必须覆盖所有内存空间，二级页表按需建立，因此可以减小存储空间

### 局部性原理

- **时间局部性**：程序中的某条指令一旦执行，则不久后该指令很可能会再次执行（循环）
- **空间局部性**：程序访问了某个存储单元，则不久后其附近的存储单元也很可能被访问（指令顺序执行、数组）

### TLB

- **多级页表缺点**：虽然解决了存储空间上的问题，但从虚拟地址到物理地址的转换步骤更加复杂，增加了时间上的开销
- **TLB**：CPU中加入一个专门存放程序最常访问页表项的Cache（TLB），也称为快表、页表缓存等

## 段页式内存管理

- 实现

  **分段**：程序划分为多个有逻辑意义的段

  **分页**：对分段划分出来的连续空间，再划分固定大小的页

- **虚拟地址**：段号、段内页号、页内偏移量

- **地址转换过程**

  第一次访问段表，得到**页表起始地址**

  第二次访问页表，得到**物理页号**

  第三次将物理页号和页内偏移量结合，得到**物理地址**

## xv6的内存管理



# 进程与线程

## 进程

### 并发与并行

- **并发**：在操作系统中，某一时间段内有几个程序在同一个CPU上运行，但**在任意一个时间点上，只有一个程序在CPU上运行**
- **并行**：两个程序在某一时刻同时运行，强调**同时发生**

### 进程状态

- **创建、就绪、阻塞、运行、终止**
- **挂起状态**：虚拟内存管理的操作系统中，可能把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行时再从硬盘换入到物理内存，描述进程没有占用实际物理内存空间的状态就是挂起状态

- **阻塞挂起状态**：进程在外存等待某个事件发生
- **就绪挂起状态**：进程在外存中，只要进入内存即可立刻运行

### 进程控制块PCB

- **作用**：PCB是进程存在的**唯一标识**，进程创建时PCB创建，进程终止时PCB销毁

- 进程描述信息

  **进程标识符PID**：标识各个进程，每个进程都有一个唯一的标识符

  **用户标识符UID**：进程归属的用户，为了共享和保护服务

- 进程控制和管理信息

  **进程当前状态**：new、ready、running、waiting或blocked等

  **进程优先级**

- **资源**分配清单

  有关内存地址空间或虚拟地址空间的信息，所**打开文件的列表**和所**使用的I/O设备信息**

- CPU相关信息

  CPU中**各个寄存器的值**，当进程切换时，CPU的状态信息被保存在进程的PCB中，以便进程重新执行时，能从断点处继续执行

#### PCB是如何组织的

- **链表**：通过链表将具有相同状态的进程的PCB链在一起，组成各种队列，如**就绪队列、阻塞队列**

### 进程的控制

#### 创建进程

- **创建进程**：操作系统允许一个进程创建另一个进程，且子进程继承父进程所拥有的资源

- **过程**

  **分配PID和PCB**：分配新的进程标识号，申请空白的PCB，若申请失败则进程创建失败

  **分配资源**：为进程分配资源，若资源不足则进程进入等待状态

  **初始化PCB**：资源分配完成后，初始化PCB

  **插入就绪队列**：将进程插入到就绪队列，等待被调度

#### 终止进程

- **查找PCB**：查找需要终止的进程的PCB
- **终止执行**：若处于执行状态，则立即终止其执行，将CPU资源分配给其他进程
- **终止子进程**：若该进程有子进程，则子进程也终止
- **归还资源**：将该进程所拥有的全部资源归还给父进程或操作系统
- **删除PCB**：将进程PCB从所在队列中删除

#### 阻塞进程

- **查找PCB**：找到被阻塞进程的PCB
- **状态转换**：若为运行状态，则保护现场（将CPU寄存器内容保存在PCB等），状态转为阻塞状态
- **插入阻塞队列**：将PCB插入到阻塞队列

#### 唤醒进程

- **唤醒**：该进程等待的事件发生，由发现者进程用唤醒语句叫醒阻塞的进程
- **查找PCB**：在该事件的阻塞队列中找到相应进程的PCB
- **状态转换**：将PCB从阻塞队列移除，转为就绪状态
- **插入就绪队列**：PCB插入就绪队列，等待队列

### 进程的上下文切换

- **上下文切换**：从一个进程切换到另一个进程运行的过程

- **CPU上下文切换**

  **寄存器和程序计数器**：执行任务前，操作系统需要帮CPU设置好CPU寄存器和程序计数器PC

  **切换**：将前一个任务的CPU寄存器和PC保存起来，加载新任务的CPU寄存器和PC，跳转到PC所指的新位置运行新任务

- **进程上下文切换**

  **进程上下文**：虚拟内存、栈、全局变量等用户空间资源，内核堆栈、寄存器等内核空间资源

  **存储**：进程上下文信息保存在进程的PCB，当运行时从PCB取出上下文恢复到CPU并继续执行

- 进程上下文切换的**场景**

  **时间片耗尽**：CPU采用时间片轮转调度时，当时间片耗尽则进程应从运行态转为就绪态

  **系统资源不足**：进程需要等待资源满足才可运行，此时它将转换为阻塞态

  **sleep**：进程通过sleep主动挂起

  **优先级更高的进程需要运行**：当前运行的进程将被挂起

  **硬件中断**：CPU上的进程会被中断挂起，转而执行内核中的中断服务程序

## 线程

- **概念**：线程是CPU调度的基本单位，同一个进程内的多个线程之间可以**共享代码段、数据段、打开的文件**等资源，每个线程各自都有**独立的寄存器和栈**

- 优点

  一个进程可以同时存在多个线程

  各个线程之间可以并发执行

  各个线程之间可以共享地址空间和文件等资源

- 缺点

  进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃

### 进程与线程的比较

- 进程是资源分配的单位，线程是CPU调度的单位
- 进程拥有完整的资源，而线程只独享必不可少的资源，如**寄存器和栈**
- 线程同样有**就绪、阻塞、执行三种状态**，以及状态之间的转换关系
- 线程能**减少并发执行的时间和空间开销**

### 线程的开销更小

- **线程创建时间比进程快**，因为线程创建不涉及资源管理信息，而是共享所属进程的资源
- **线程终止时间比进程快**，因为线程释放的资源比进程少很多
- **同一个进程内的线程切换比进程切换快**，因为线程具有相同的地址空间（虚拟内存共享），切换时无需切换页表
- **同一个进程内的线程数据交互效率更高**，同一进程的各个线程之间共享内存和文件资源

### 线程的上下文切换

- 两个线程属于不同进程时，切换过程与进程上下文切换一致
- 两个线程属于同一个进程，则虚拟内存等资源无需切换，只需切换线程的寄存器、程序计数器等数据

### 线程的实现

- **用户线程**：用户空间实现的线程，由用户态的线程库完成管理

- **内核线程**：内核中实现的线程，由内核管理

- **轻量级进程**：在内核中支持用户线程

- 用户线程和内核线程的对应关系

  **多对一**：多个用户线程对应同一个内核线程

  **一对一**：一个用户线程对应一个内核线程

  **多对多**：多个用户线程对应多个内核线程

- **线程控制块TCB**

## 进程调度

### 调度原则

- **CPU利用率**
- **系统吞吐量**：单位时间内CPU完成进程的数量
- **周转时间**：进程运行和阻塞时间的总和
- **等待时间**：进程处于就绪队列的时间
- **响应时间**：从用户提交请求到系统第一次产生响应所花费的时间

### 调度算法

- **先来先服务FCFS**

- **最短作业优先SJF**

- **高响应比优先算法**

  优先权=(等待时间+要求服务时间)/要求服务时间

- **时间片轮转调度算法**

- **最高优先级调度算法**
- **多级反馈队列调度算法**

## 进程间通信

### 管道

- **Linux命令中的管道**：竖线`|`将前一个命令的输出作为后一个命令的输入，如下将ps auxf的输出作为grep mysql的输入

```shell
$ ps auxf | grep mysql
```

- **单向**：管道传输数据是单向的，如果想相互通信需要创建两个管道

- **匿名管道**：`|`表示的管道称为匿名管道，用完了就销毁

- **命名管道**：也叫做`FIFO`，因为数据是先进先出的传输方式。通过`mkfifo`命令创建并指定管道名字，命名管道以文件的方式存在，类型为p（pipe）

```shell
$ mkfifo myPipe
$ echo "hello" > myPipe	// 将数据写进管道
```

```shell
$ cat < myPipe			// 读取管道数据
hello
```

#### 匿名管道创建的原理

- **pipe系统调用**：返回两个描述符，分别是管道的读取端描述符`fd[0]`，另一个是管道的写入端描述符`fd[1]`

```c
int pipe(int fd[2]);
```

- **管道是内核里的一段缓存**：写入管道的数据实际上是缓存在内核中的，从管道读取数据实则从内核中读取数据

#### 父子进程通信

- **管道描述符复制**：父进程使用fork创建子进程，子进程会复制父进程的文件描述符，因此子进程也拥有该管道的读取端、写入端的描述符
- **单向通信**：父进程关闭读取端描述符`fd[0]`，保留写入端`fd[1]`；子进程关闭写入端`fd[1]`，保留读取端`fd[0]`，这样父进程往管道写入的数据就能被子进程读取
- **双向通信**：如果需要双向通信，则应该创建两个管道

#### 匿名管道和命名管道的区别

- **匿名管道**：**通信范围**是存在**父子关系的进程**，管道没有实体，没有管道文件，因此该管道只能通过fork复制父进程文件描述符，来达到通信的目的
- **命名管道**：可以在**不相关的进程**间相互通信，命名管道创建了类型为管道的设备文件，进程只要使用这个设备文件，就可以相互通信

- **共同点**：数据都是缓存在内核中，数据遵循FIFO原则

### 消息队列

- **链表**：消息队列是保存在内核中的消息链表，发送数据时会分成多个独立的数据单元，即消息体。进程从消息队列中读取了消息体，内核就把该消息体删除
- **消息队列不阻塞进程**：A进程要给B进程发送消息，则A进程只要把数据放在对应的消息队列后就可正常返回，B进程需要的时候再去读取数据即可

- **消息队列存在用户态与内核态之间的数据拷贝开销**：进程写入数据到内核中的消息队列时，需要把数据从用户态拷贝到内核态；进程读取消息队列的数据时，需要将数据从内核态拷贝到用户态

### 共享内存

- **优点**：消息队列在进行读取和写入时，都得进行内核态与用户态之间的数据拷贝，共享内存则解决了该问题

- **虚拟内存**：每个进程都有独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存，因此两个进程相同的虚拟地址对应着不同的物理内存地址
- **共享内存**：将一块虚拟地址空间映射到相同的物理内存中，进程A写入的内容将立刻被进程B看见，无需进行拷贝，大大提高了进程间通信的速度

### 信号量

- **共享内存的问题**：如果多个进程同时修改同一个共享内存，则部分进程的修改将被其他进程覆盖，造成数据错乱

- **保护机制**：为了防止多进程竞争共享资源，造成数据错乱，需要保护机制，是的共享资源在任意时刻只能被一个进程访问

- **信号量**：一个整型的计数器，主要用于实现进程间的互斥与同步

- **控制信号量的两种原子操作**

  **P操作**：把信号量减去1，相减后若信号量小于0，则表明资源已被占用，进程需要阻塞等待；若相减后信号量大于等于0，则表明还有资源可用，进程可正常继续执行

  **V操作**：把信号量加上1，相加后若信号量小于等于0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量大于0，则表明没有阻塞中的进程

- **互斥信号量**：**信号初始化为1**，则保证共享资源在任何时刻只有一个进程在访问，因此为互斥信号量
- **同步信号量**：**信号初始化为0**，假如必须保证进程A在进程B之前执行，则进程A在最后执行V操作，进程B在最开始执行P操作

### 信号

- **信号**：**异常情况**下，需要用信号的方式通知进程

- **Linux信号**

  对于运行在shell终端的进程，可以通过键盘输入某些组合键给进程发送信号，如

  **终止进程**：Ctrl+C产生SIGINT信号，表示终止进程

  **停止进程**：Ctrl+Z产生SIGTSTP信号，表示停止进程，但还未结束

  如果进程在后台运行，可以通过**kill命令和进程PID**给进程发送信号，如

  `kill -9 1050`，表示给PID为1050的进程发送SIGKILL信号，用来立即结束该进程

### Socket

- **Socket通信**：跨网络与不同主机上的进程之间通信，也可以在同主机上进程间通信

- 创建socket的系统调用

  ```c
  int socket(int domain, int type, int protocol);
  ```

  domain指定协议族，比如AF_INET用于IPv4，AF_INET6用于IPv6，AF_LOCAL用于本机

  type指定通信特性，如SOCK_STREAM表示字节流，对应TCP；SOCK_DGRAM表示数据报，对应UDP；SOCK_RAW表示原始套接字

  protocol用于指定通信协议，现在基本废弃

#### 基于TCP协议通信的socket编程模型

- 过程

  **初始化socket**：服务端和客户端初始化socket，得到文件描述符

  **绑定**：服务端调用bind，绑定在IP地址和端口

  **监听**：服务端调用listen进行监听

  **accept**：服务端调用accept等待客户端连接，客户端发起连接后，accept返回用于传输的socket的文件描述符

  **发起连接**：客户端调用connect向服务端的地址和端口发起连接请求

  **数据传输**：客户端调用write写入数据，服务端调用read读取数据

  **断开连接**：客户端调用close，服务器调用read读取数据时会读取到EOF，处理完数据后服务端调用close表示连接关闭

- 两个socket

  **监听socket**：服务端进行监听的socket

  **已完成连接socket**：用于传送数据的socket

#### 基于UDP协议通信的socket编程模型

- **初始化socket**
- **绑定**：每个UDP的socket都需要绑定IP地址和端口
- **sendto**：向目标主机的IP地址和端口发送数据
- **recvfrom**：接收源主机IP地址和端口的数据
- **无连接**：UDP是无连接的，因此不需要三次握手，也不需要调用listen和connect

#### 针对本地进程间通信的socket编程模型、

- **效率提高**：编程接口和IPv4、IPv6套接字编程接口一致，支持字节流、数据报两种协议，但实现效率大大提高
- **绑定**：本地字节流socket和本地数据报socket在bind时，并非**绑定IP地址和端口**，而是**绑定本地文件**

## 多线程同步

### 互斥

- **race condition**：多线程相互竞争操作共享变量时，由于在执行过程中发生了上下文切换，得到了错误的结果
- **临界区**：访问共享资源的代码片段，不能给多线程同时执行

- **互斥**：一个线程在临界区执行时，其他线程应该被阻止进入临界区

### 同步

- **同步**：并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通消息称为进程/线程同步。即多个进程/线程在合作共同完成任务时，需要有一定的先后执行顺序的制约。

### 互斥与同步的实现和使用

#### 锁

- **加锁**：任何进入临界区的线程，必须先执行加锁操作，加锁成功则进入临界区，否则阻塞
- **解锁**：完成对临界资源的访问后执行解锁操作，以释放该临界资源

- **原子操作指令Test-and-Set**

  ```c
  int TestAndSet(int *old_ptr, int new) {
      int old = *old_ptr;
      *old_ptr = new;
      return old;
  }
  ```

  **功能**：该指令由硬件完成，把old_ptr更新为new的值，并返回old_ptr的旧值

  **原子性**：要么全部执行，要么都不执行，不会出现执行到一半的中间状态

- **使用原子操作指令实现忙等待锁**

  ```c
  typedef struct lock_t {
      int flag;
  } lock_t;
  
  void init(lock_t *lock) {
      lock->flag = 0;
  }
  
  void lock(lock_t *lock) {
      while (TestAndSet(&lock->flag, 1) == 1)
      ;	// do nothing
  }
  
  void unlock(lock_t *lock) {
     	lock->flag = 0;
  }
  ```

  **flag的含义**：flag为1代表该锁被某个线程持有，否则代表该锁未被持有

  **加锁时的操作**：假如该锁已被其他线程持有，则`lock->flag`为1，执行`TestAndSet(&lock->flag, 1)`不会改变flag的值，而且会读取到1，此时while循环条件满足，将继续循环；若该锁被其他线程释放，则`lock->flag`为0，执行`TestAndSet(&lock->flag, 0)`会改变flag的值，从而获取该锁，同时读取到原来的值0，将跳出循环，并执行临界区代码

- **自旋锁**：当获取不到锁时，线程会一直执行while循环而不做任何其他事情，因此称为忙等待锁，也叫自旋锁spin lock

- **无等待锁**：获取不到锁时，线程放入到锁的等待队列，当前线程阻塞，CPU会调度其他线程执行。待持有锁的线程释放锁时，将唤醒该锁的等待队列中的某个线程让其获取锁并继续执行

#### 信号量

- **含义**：信号量通常表示资源的数量，对应一个整型变量

- **原子操作**

  **P操作**：将信号量减1，若**信号量小于0则阻塞等待**，否则继续执行

  **V操作**：将信号量加1，若**信号量小于等于0则唤醒一个等待中的线程/进程**

### C++实现信号量机制

```c++
#include <condition_variable>
#include <mutex>
#include <unique_lock>
using namespace std;

class Semaphore {
private:
    int count;
    mutex mtx;
    condition_variable cv;
    
public:
    Semaphore(int count = 1): count(cnt) {}
    
    void acquire() {
        unique_lock<mutex> guard(mtx);
        while (count <= 0)
        	cv.wait(guard);
       	--count;        
    }
    
    void release() {
        lock_guard<mutex> guard(mtx);
        ++count;
        cv.notify_all();
    }
};
```



### 生产者-消费者问题

- **问题描述**：生产者生成数据后，放在缓冲区中；消费者从缓冲区取出数据处理；任何时刻，只能有一个生产者或消费者可以访问缓冲区

- 问题分析

  **互斥访问缓冲区**：任何时刻只有一个线程能访问缓冲区，需要设置互斥信号量保护缓冲区

  **缓冲区空**：消费者必须等待生产者生成数据

  **缓冲区满**：生产者必须等待消费者取出数据

- 信号量设置

  **互斥信号量mutex**：用于互斥访问缓冲区，初始化值为1

  **资源信号量full**：用于消费者询问缓冲区是否有数据，有数据则读取，无数据则阻塞，初始化为0（表示缓冲区初始为空）

  **资源信号量empty**：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为n（缓冲区大小）

- 实现

  ```c
  int N = 10;	// buffer size
  Semaphore mutex(1);
  Semaphore full(0);
  Semaphore empty(N);
  
  void consumer() {
      while (true) {
          P(full);
          P(mutex);
          read();
          V(mutex);
          V(empty);
      }
  }
  
  void producer() {
      while (true) {     
          P(empty);
          P(mutex);
          write();
          V(mutex);
          V(full);
      }
  }
  ```

  **先获取full或empty信号量，再获取互斥锁mutex**：如果先获取mutex则会导致死锁，假设当前缓冲区为空，消费者获取了mutex，然后尝试获取full失败并阻塞，但它仍然持有mutex。此时，生产者想要生成数据必须先获取mutex，由于已被持有因此生产者也会被阻塞，造成死锁

### 哲学家进餐问题

- 限制就餐人数为N-1
- 指定拿筷子规则，奇数哲学家先拿左手，偶数哲学家先拿右手

### 读者-写者问题

- **问题描述**：多个读者可以共同访问，但是写者必须单独访问（不能与其他读者共同访问，也不能与其他写者共同访问）

- **实现**

  ```c
  Semaphore rMutex(1);		// 访问读者计数器rCount的互斥量
  Semaphore wMutex(1);		// 读者与写者互斥访问文件的互斥量
  Semaphore flag(1);			// 读者与写者互斥访问wMutex的互斥量
  int rCount = 0;				// 读者计数
  
  void writer() {
      while (1) {
          P(flag);
          P(wMutex);
          write();
          V(wMutex);
          V(flag);
      }
  }
  
  void reader() {
      while (1) {
          P(flag);
          P(rMutex);
          if (rCount == 0) {
              P(wMutex);			// 第一个读者进入时, 需要阻塞写者写操作
          }
          ++rCount;
          V(rMutex);
          V(flag);
          read();
          P(rMutex);
          --rCount;
          if (rCount == 0) {
              V(wMutex);			// 没有读者了, 唤醒阻塞中的写者
          }
          V(rMutex);
      }
  }
  ```

  

## 死锁

### 死锁的必要条件

- 互斥访问
- 不可抢占
- 占有并等待
- 环路等待

### 解决方法

- 死锁预防
- 死锁检测与恢复
- 死锁避免：银行家算法

## 锁

### 互斥锁与自旋锁

- **互斥锁**：加锁失败后，线程**释放CPU**给其他线程
- **自旋锁**：加锁失败后，线程会忙等待（**占用CPU**），直到拿到锁

- **互斥锁的开销成本**：当线程获取互斥锁失败时将被阻塞，线程从运行切换为阻塞状态，从用户态陷入内核态，内核完成线程切换；当该互斥锁被其他线程释放时，之前睡眠的线程变为就绪状态，内核会在合适的时间把CPU切换到该线程运行。因此互斥锁的开销成本为两次线程上下文切换的成本
- **自旋锁的开销成本**：自旋锁通过CPU提供的CAS函数（Compare And Swap）在用户态完成加锁和解锁操作，无需进行线程上下文切换，但是会一直占用CPU
- **选择**：如果临界区代码执行时间很短，则不应该用互斥锁，而是用自旋锁；若临界区代码执行时间较长，则使用互斥锁，因为此时使用自旋锁将导致较长时间内CPU资源的浪费

### 读写锁

- **原理**：写锁是独占锁，读锁是共享锁
- **应用**：读写锁在读多写少的场景，能发挥出优势

### 乐观锁与悲观锁

- **悲观锁**：认为多线程同时修改共享资源的概率较高，很容易出现冲突，所以**访问共享资源前先上锁**
- **乐观锁**：认为多线程同时修改共享资源的概率较低。**先修改**共享资源，**再验证**这段时间内有没有发生冲突，如果没有其他线程修改资源则操作完成，否则**放弃本次操作并重试**

# 调度算法

## 进程调度算法

- 先来先服务调度算法FCFS
- 最短作业优先调度算法SJF
- 高响应比优先调度算法
- 时间片轮转调度算法
- 最高优先级调度算法
- 多级反馈队列调度算法

## 页面置换算法

### 缺页中断

- **缺页中断**：当CPU访问的页面不在物理内存时，则产生一个缺页中断，请求操作系统将所缺页调入到物理内存

- 缺页中断的处理流程

  **执行指令**：Load M指令，CPU寻找M对应的页表项

  **页表项无效，发出缺页中断**：如果该页表项的状态位是无效的，则CPU发送缺页中断请求

  **缺页中断处理函数**：操作系统收到缺页中断，执行缺页中断处理函数，查找该页面在磁盘中的页面的位置

  **换入**：在物理内存中找到空闲页，把该页面从磁盘换入到内存中

  **修改页表项为有效的**：把该页的页表项的有效位修改为有效的

  **重新执行指令**：CPU重新执行导致缺页异常的指令

- **页面置换**：物理内存没有空闲页时，则需要进行页面置换，选择一个物理页，若其dirty位置位，则换出到磁盘，并将其页表项改为无效的。然后把需要访问的页从磁盘换入到物理内存

- **页表项：页号、物理页号、有效位、访问字段、dirty位、硬盘地址**

### 虚拟内存访存的整体流程

- **检查虚拟地址**：程序通过虚拟地址访问某个页面，先检查该地址是否有效
- **检索TLB、访问页表**：若有效则检索TLB，TLB命中则得到了该页表项；否则访问页表，并将该页表项更新至TLB
- **检查页表项有效位、缺页中断**：检查该页表项有效位，若无效则发送缺页中断，由操作系统从磁盘中找到缺页并换入内存，若需要进行页面置换则检查该页面是否dirty，若是还需要将其写入磁盘
- **置访问位、dirty位**：修改该页的页表项的访问位和dirty位
- **得到物理地址**：将物理页号和页内偏移量组合得到物理地址，最后访问该地址

### 页面置换算法

- **最佳页面置换算法OPT**
- **先进先出置换算法FIFO**
- **最近最久未使用LRU**
- **时钟页面置换算法Lock**
- **最不常用置换算法LFU**



# I/O模型

- 一个输入操作通常包括**两个阶段**

  **等待数据到来**：等待数据准备好

  **拷贝数据**：从内核向进程复制数据

- 对于套接字上输入操作的两个阶段

  **等待数据从网络到来**：等待数据从网络中到达，到达后数据被复制到内核中的某个缓冲区

  **拷贝数据**：把数据从内核缓冲区复制到应用进程缓冲区

## 阻塞I/O

- 应用进程被阻塞，直至**数据从内核缓冲区复制到应用进程缓冲区**才返回
- 阻塞时，CPU调度将执行其他线程/进程

## 非阻塞I/O

- **轮询**：应用进程执行系统调用后，内核返回一个错误码，应用进程可以继续执行，但是需要**不断执行系统调用以获知I/O是否完成**

- **缺点**：应用进程需要进行多次系统调用，**CPU利用率较低**

## I/O复用

- **等待数据**：使用select或poll等待数据，等待多个套接字中的任何一个变为可读，此过程会被阻塞
- **读取数据**：某一个套接字可读时返回，使用`recvfrom`系统调用把数据从内核复制到进程中

- **优点**：单个进程具有处理多个I/O事件的能力，又称为事件驱动I/O

## 信号驱动I/O

- **sigaction系统调用**：应用进程使用sigaction系统调用，内核立刻返回，等待数据阶段是非阻塞的
- **数据到达**：内核在数据到达时向应用进程发送SIGIO信号，应用进程收到后在信号处理程序中调用recvfrom将数据从内核复制到应用进程中
- **优点**：相比于非阻塞式的I/O轮询方式，提高了CPU利用率

## 异步I/O

- **aio_read系统调用**：应用进程执行aio_read系统调用后立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成后向应用进程发送信号

- **异步I/O与信号驱动I/O的区别**

  异步I/O的信号是**通知应用进程I/O完成**（数据已经复制到应用进程缓冲区）

  信号驱动I/O的信号是**通知应用进程可以开始I/O**（数据已经到达内核缓冲区，需要调用recv_from将数据拷贝到应用进程缓冲区）

## 同步I/O与异步I/O的区别

- **同步I/O**：将数据从内核缓冲区复制到应用进程缓冲区阶段，应用进程会被阻塞
- **异步I/O**：上述第二阶段不会被阻塞

## I/O多路复用

### select

- **功能**：允许应用程序监视一组文件描述符，等待一个或多个描述符称为就绪状态，从而完成I/O操作

- **参数**

  fd_set：文件描述符集合，使用数组实现，数组大小固定为FD_SETSIZE（Linux中为1024）。三种类型的描述符类型为readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合

  timeout：超时参数，调用select会一直阻塞直到有描述符的时间到达，或等待的时间超过了timeout

- **返回值**：调用成功返回结果大于0，超时返回0，出错返回-1

### poll

- **功能**：poll的功能与select类似，也是等待一组描述符中的任意一个成为就绪状态

- **描述符数量限制**：select使用数组实现文件描述符集合，数组大小为1024，poll没有描述符数量限制

- 缺点

  **速度较慢**，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区

### epoll

- 接口

  `epoll_create`用于让内核创建一组大小为size的文件描述符集合

  `epoll_ctl`用于向内核注册新的描述符或改变某个文件描述符的状态

  `epoll_wait`获取事件完成的文件描述符集合

```c
int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
```

- **数据结构**：已注册的描述符在内核中被维护在一棵**红黑树**上，通过回调函数，内核会将I/O已准备好的描述符加入到一个**链表**中管理，通过epoll_wait系统调用就能得到事件完成的文件描述符集合

- **触发模式**

  **水平触发level trigger**：调用epoll_wait检测到描述符事件到达时，将事件通知进程，进程可以不立即处理该事件，下次调用epoll_wait时会再次通知进程

  **边沿触发edge trigger**：描述符事件到达后，通知进程，进程必须立即处理事件，否则下次再次调用epoll_wait不会再得到事件到达的通知

- 优缺点

  **优点**：所有文件描述符都存在于内核中，**无需**进行从用户进程缓存到内核缓存的文件描述符集合**拷贝**

  **缺点**：每次**修改**文件描述符状态都需要**通过epoll_ctl()系统调用**

### 比较

- **时间精度**：select的时间精度为微秒，而poll和epoll为毫秒，因此**select适用于实时性要求更高的场景**
- **描述符数量限制**：select上限为1024，poll和epoll无限制
- **文件描述符存储位置**：select和poll存储在用户进程，每次系统调用都需要进行从用户进程缓冲区到内核缓冲区的拷贝，epoll存储在内核。因此如果需要**监听处理大量文件描述符时，使用epoll效率更高**
- **可移植性**：select几乎被所有主流平台所支持，epoll只能运行在linux平台
