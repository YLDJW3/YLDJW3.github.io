---
title: OS-内存管理
date: 2022-03-03 10:50:21
tags: 
    - OS
    - 面试
mathjax: true
categories: OS
---

**操作系统内存管理重要知识总结**

<!--more-->

# 内存管理

## 2 内存管理策略

### 2.1 基本概念

- 高速缓存
- 内存空间保护
  - 每个进程都有单独的内存空间，**基地址寄存器（重定位寄存器）**、**界限地址寄存器**
  - 用户进程试图访问操作系统的内存空间或其他用户的内存空间，将trap进入内核态，操作系统将该程序中止
  - 只有内核态中能修改基地址寄存器和界限地址寄存器
- 内存调度，将进程从外存调度进入内存，等待调到内存以便执行的进程形成了输入队列
- 地址绑定，将指令和数据绑定到存储器地址
  - 编译时绑定，生成绝对代码
  - 加载时绑定，生成可重定位代码（开始地址可变、相对于该开始地址的位置确定）
  - 运行时绑定
- 逻辑地址空间、物理地址空间
  - CPU生成的地址为逻辑地址
  - 加载到内存地址寄存器中的地址为物理地址
- 内存管理单元MMU，从**虚拟地址**到**物理地址**的运行时映射由**MMU硬件完成**

### 2.2 交换

- 交换指进程暂时从**内存**交换到**备份存储**（通常是快速磁盘），再次执行时再**调回内存**
- **标准交换**过程：操作系统维护进程的就绪队列，当CPU调度器决定执行一个进程时，检查队列中的下一个进程是否位于内存，如果不在且内存没有空闲区域，则将一个内存中的进程换出，将该进程换入，并将控制器转移到所选进程

- 换出进程时，必须确保其处于完全空闲状态，如等待I/O的进程不能直接换出
- 交换的**转移时间**与所交换的**内存空间大小成正比**

### 2.3 连续内存分配（早期方法）

- **内存保护**，CPU将用户进程想访问的地址与重定位寄存器、界地址寄存器进行对比，以确保它只访问其内存空间中的地址
- **固定分区**的内存分配，内存划分为多个分区，每个分区可包含一个进程，当分区空闲时将进程调入内存，多道程序的数量受限于**分区数**
- **可变分区**的内存分配，操作系统维护一个**表**记录**哪些内存可用、哪些内存已用**
  - 可理解为有序区间列表
  - 为进程分配空间时存在不同方案：**首次适应、最优适应、最差适应**
  - 如果无法为该进程分配空间，则考虑等待，或尝试为就绪队列中的其他进程分配空间

- **碎片**
  - **外部碎片**，当采用可变分区的内存分配时，空闲内存空间会被划分小的片段，形成大量的小孔
  - **内部碎片**，按固定大小的块来分配内存，因此进程可能分得比其所需空间更大的内存，称为内部碎片
  - **紧缩**，通过移动内存内容解决外部碎片问题，但代价较高，且只能用于运行时重定位的进程
  - 通过**不连续内存分配**可解决外部碎片问题

### 2.4 分段

- 逻辑地址空间由一组**段**构成，每个段都有**名称和长度**
- 逻辑地址是由**段名称**和**段偏移**构成的二元组
- 通过**段表**将该逻辑地址映射到实际物理地址，每个条目包含**段基地址**和**段界限**
- 逻辑地址的**段偏移$d$**应该位于**0到段界限之间**，否则会**陷入**操作系统，终止该用户进程
- 如果逻辑地址的**段偏移$d$**合法，则将其**与段基地址相加得到物理内存地址**

### 2.5 分页

#### 基本方法

- **帧、页帧**frame，物理内存的一块

- **页、页表**page，逻辑内存的一块，大小与帧相等

- **块**，快速存储分块，大小与帧相等

- 逻辑地址由**页码**和**页偏移**组成

- **页表**将逻辑地址映射为物理地址，页表项保存**该页的物理内存的基地址**

- **页的大小**通常选为**2的幂**，原因是？

  **便于将逻辑地址转为物理地址**，假设逻辑地址空间大小为$2^m$，而页的大小为$2^n$，则逻辑地址的前$m-n$位为页码，而后面的$n$位是页偏移。根据页码在页表中查得对应的页表项，将页表项中的页基地址加上页偏移即得到了物理地址

#### 硬件支持

- 操作系统为每个进程分配一个页表，页表的指针存入进程控制块PCB，进程运行时其**页表位于内存**，并将**页表指针**放入**页表基地址寄存器**
- 访问用户一个字节需要**执行两次访存**，首先根据逻辑地址查找内存中的**页表**，将得到的帧基地址加上页偏移得到**真实物理地址**，再去**访问该物理地址**对应的内存位置
- 为了提高效率，引入了**转换表缓冲区TLB**，是关联的高速内存。当访问内存时，先在TLB中查找，找不到（**TLB未命中**）再**查询页表**

#### 保护

- 分页环境下的内存保护，通过**每个帧关联的保护位**实现
- 用一个位定义一个页是**可读可写或只读**
- **有效-无效位**，表示页是否处于进程的逻辑地址空间内

### 2.6 页表结构

#### 分层分页

- 目的：为了减少**页表**所占的内存空间
- **两层分页算法**
  - 页表分页，如32位逻辑地址空间，页大小为4K，则逻辑地址分为20位的页码和12位的页偏移
  - 将20位的页码分为**10位的顶层页码**和**10位的内层页码**，首先根据前10位在**顶层页表**找到对应的表项，它保存了某个**内层页表的基地址**
  - 取出后再访问该**内部页表**，并用中间10位再内层页表中找到对应的表项，它保存了**某个页的基地址**
  - 取出该**基地址**，加上12位的**页偏移**，便得到了逻辑地址对应的**物理地址**，访问该物理内存即可

### 2.7 补充：xv6中的内存分页

- xv6的虚拟地址是64位的，使用低39位用于寻址
- xv6页的大小为4KB，因此页偏移占据12位，页码占据27位
- 页表共包含$2^{27}$个页表项（PTE），每个页表项包含44位的页的基地址（PPN）和10位的标志位
- MMU取虚拟地址低39位中的前27位索引PTE，并将其44位的PPN与原虚拟地址12位的页偏移拼接得到56位的物理地址
- xv6的分层分页
  - 27位的页码分为三层，每层占据9位，分别称为**L2、L1、L0索引**
  - 先用L2索引在顶级页表（1个）中索引PTE，从中取出PPN，是某个中级页表的基地址
  - 再取L1索引在中极页表中索引PTE，从中取出PPN，是某个低级页表的基地址
  - 再取L0索引再低级页表中索引PTE，从中取出44位的PPN并与12位的页偏移组成56位的物理地址

- 分层分页结构的**优点**
  - xv6的逻辑地址空间为39位，页大小为4KB，因此总共包含$2^{27}$个页
  - 假如某个进程只使用了1个页，**采用不分层结构**，则它仍然需要存储$2^{27}$个页表项，而每个页表项的大小为8B，因此**占据了1GB，共$2^{18}$个页表**
  - 而进程**使用分层结构**，由于只使用了1个页，因此只需要1个顶层页表、1个中层页表、1个底层页表，共3个页表，**包含$3*2^9$个页表项，因此占据了12KB**



## 3 虚拟内存管理

- Lazy allocation
- Zero fill on demand
- Copy on Write Fork
- Demand Paging
- Memory Mapped Files

### 3.1 基础

- 许多情况**不需要把整个程序置于内存中**也可运行，如
  - 部分代码几乎**从不执行**（异常处理）
  - **数组**等所分配的内存**远多于实际需要的值**
  - 某些选项和功能很少使用
- 虚拟内存将用户**逻辑内存**与**物理内存**分开
- 虚拟内存允许文件和内存通过**共享页**而为多个进程所共享

### 3.2 请求调页Demand paging

- **请求调页**技术的实现
  - 进程的部分页面驻留在外存上
  - 进程的页表包含**有效-无效位**，有效意味着该页**属于该进程**，且**位于内存中**
  - 当进程访问有效页时，可以直接访问在内存中的页面
  - 当进程访问**无效页**时，将产生**page fault（缺页错误）**，**陷入**操作系统
  - 操作系统处理page fault的过程
    - 检查进程的**内部表**确定该引用是有效还是无效的内存访问
    - 如果引用无效则终止进程，如果有效但尚未调入页面，则现在调入
    - 找到**空闲帧**，并将页面调入该帧
    - **修改**进程的**内部表和页表**，指示该页已位于内存中
    - 返回到**用户态**，进程**重新执行**引发陷入的**指令**，由于该页面已位于内存中，因此进程可以正常执行该指令
- 支持demand paging的**硬件**
  - **页表**，通过有效-无效位标记页表项是否属于进程且位于内存中
  - **外存**，用于保存进程不在内存中的页面

### 3.3 写时复制Copy-on-Write

- 系统调用`fork()`创建**父进程的一个复制**，以作为**子进程**，`fork()`为子进程创建一个父进程**地址空间的副本**，**复制属于父进程的页面**
- 然而子进程大多在创建后立即调用`exec()`，父进程地址空间的复制没有必要，可使用**写时复制copy-on-write技术**

- 写时复制copy-on-write技术
  - 创建子进程时，父进程和子进程最初共享相同的页面工作，**子进程**页表的**PTE指向父进程**相应的物理内存**page**
  - 这些共享页面**标记为写时复制**
  - 如果任何一个进程（父进程或子进程）**写入共享页面**，会导致**page fault并陷入**，在内核中需要
    - **创建**物理page
    - 将内容**拷贝**过去以得到共享页面的副本
    - 修改进行写操作的进程页表的**PTE**，使其**指向该副本**
    - 父进程和子进程的页表的相关PTE的**copy-on-write标志清除**
    - 返回到用户空间，**重新执行用户指令**

### 3.4 页面置换

#### FIFO

- 置换**最早被换入内存**的页

#### OPT最优页面置换

- 置换**最长时间不会使用**的页面，需要引用串的未来知识，实践中难以实现，常用于与其他算法的比较研究

#### LRU

- 手撕LRU，**双向链表 + 哈希表**

```c++
class Node {
public:
    int key;
    int value;
    shared_ptr<Node> prev;
    shared_ptr<Node> next;
    Node(int k = 0, int v = 0): key(k), value(v) {} 
};
class LRUCache {
public:
    int capacity_;
    shared_ptr<Node> head;
    shared_ptr<Node> tail;
    int size_;
    unordered_map<int, shared_ptr<Node>> f;
    LRUCache(int capacity): capacity_(capacity), head(make_shared<Node>()), tail(make_shared<Node>()), size_(0), f({}) {
        head->next = tail;
        tail->prev = head;
    }

    void top(shared_ptr<Node> p) {
        p->prev->next = p->next;
        p->next->prev = p->prev;
        p->next = head->next;
        p->next->prev = p;
        head->next = p;
        p->prev = head;
    }
    int get(int key) {
        int ans = -1;
        if (f.count(key)) {
            ans = f[key]->value;
            top(f[key]);
        }
        return ans;
    }
    void put(int key, int value) {
        if (f.count(key)) {
            f[key]->value = value;
            top(f[key]);
        } else {
            auto p = make_shared<Node>(key, value);
            f[key] = p;
            p->next = head->next;
            p->next->prev = p;
            head->next = p;
            p->prev = head;
            if (f.size() > capacity_) {
                auto p = tail->prev;
                tail->prev = p->prev;
                p->prev->next = tail;
                auto it = f.find(p->key);
                f.erase(it);
            }
        }
    }
};
```

- **近似LRU**
  - 额外引用位
  - 第二次机会算法
  - 增强型第二次机会算法

#### 基于计数的页面置换

- **LFU**
- **MFU**

- 手撕LFU

  - 通过`set`实现，需要**重载`<`**实现排序规则
  - 注意**无法修改`set`中的元素**，因此必须先取出，修改后再放回

  ```c++
  class Node {
  public:
      int key;
      int value;
      int cnt;
      int t;
      Node(int k=0, int v=0, int time = 0): key(k), value(v), cnt(1), t(time) {}
      bool operator<(const Node& rhs) const { 
          return this->cnt == rhs.cnt? this->t < rhs.t: this->cnt < rhs.cnt; 
      }
  };
  
  class LFUCache {
  public:
      int capacity_;
      set<Node> s{};
      unordered_map<int, Node> f{};
      int t = 0;
      LFUCache(int capacity): capacity_(capacity) {}
      
      int get(int key) {
          if (f.count(key)) {
              auto node = f[key];
              s.erase(node);
              ++node.cnt;
              node.t = t++;
              s.insert(node);
              f[key] = node;
              return node.value;
          }
          return -1;
      }
      
      void put(int key, int value) {
          if (capacity_ == 0)
              return;
          if (f.count(key)) {
              auto node = f[key];
              s.erase(node);
              ++node.cnt;
              node.t = t++;
              node.value = value;
              f[key] = node;
              s.insert(node);
          } else {
              if (s.size() == capacity_) {
                  auto node = f[s.begin()->key];
                  f.erase(node.key);
                  s.erase(s.begin());
              }
              Node node = Node(key, value, t++);
              s.insert(node);
              f[key] = node;
          }
      }
  };
  ```

  

### 3.5 帧分配

#### 帧的最小数

- 如果允许**每条指令的内存引用最大数目**为$x$，则运行时一个进程至少要分配$x+1$帧，否则它执行该指令会引发page fault，且其所拥有的帧都无法换出，（后果或许是，进程不得不终止）

#### 分配算法

- **平均**分配
- **比例**分配
- 结合**优先级**和比例分配

#### 全局分配与局部分配

- **全局分配**，允许一个进程从另一个进程处获取帧
- **局部分配**，进程只能置换自己拥有的帧
- **全局置换**使得进程不能控制其缺页错误率，但往往有**更好的系统吞吐量**

### 3.6 系统抖动

- 刚刚换出的页面马上又要换入内存，刚刚换入的页面又要马上换出内存，如果一个进程在**页面置换的时间多于执行时间**，则进程在**抖动**
- 原因是**进程频繁访问的页面数量**高于**可用的物理页帧数目**

### 3.7 内存映射文件memory-mapped file

- 内存映射文件，将**文件I/O**作为**常规内存**访问，将每个磁盘块映射到一个或多个内存页面
- **lazy**：文件访问按普通请求调页进行，从而产生**缺页错误**，然后文件的页面**从文件系统读取到物理页面**，此后文件读写就可按常规内存访问处理了
- 内存映射文件写入，**不一定**对磁盘文件**同步**写入，操作系统**定期检查文件的内存映射页面是否被修改**，以便选择是否更新到磁盘文件
- **关闭文件**时，**所有**内存映射的数据都**写入磁盘文件**，并从打开它的进程的虚拟内存中删除
- **多个进程**并发地对**同一文件内存映射**，可实现**数据共享**。任何一个进程写入该内存映射文件，其他映射同一文件的进程都可以看到，因为每个进程的虚拟内存映射**指向物理内存的同一页面**

