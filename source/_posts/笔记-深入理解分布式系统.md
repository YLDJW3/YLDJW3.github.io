---
title: 笔记-深入理解分布式系统
date: 2022-05-29 15:38:43
tags: 
    - Distributed System
mathjax: true
categories: Distributed System
---

# 认识分布式系统

## What

- 分布式系统是将组件分布在不同的、联网的计算机上，组件之间通过网络传递消息进行通信、协调，以共同完成一个任务的系统
- 以下名词，均指代分布式系统中的一员
  - 节点
  - 进程
  - 计算机
  - 服务器
  - 组件
  - 副本

## Why

- 高性能：多台计算机组成拥有大量CPU、内存、磁盘的分布式系统
- 可扩展性：扩大规模
- 高可用性：冗余、服务切换

## Example

### 搜索引擎

- 分布式文件系统GFS，分布式存储系统Bigtable
- 分布式锁服务Chubby
- 分布式计算编程模式MapReduce
- 分布式数据库Spanner

### 加密货币

- 比特币，首次实现和验证了一种使用的、去中心化和拜占庭容错的共识算法
- 区块链在隐私和数据保护方面的优点

## Challenge

- 网络延迟问题：丢包、延迟、重传、乱序
- 部分失效：系统部分节点宕机，与原子性之间的矛盾
- 时钟问题：每台机器的本地时钟不一致

## 重要的数字

- **执行一个指令**：1ns
- L1缓存查询：0.5ns
- L2缓存查询：4ns
- 主存访问：100ns
- **从内存顺序读取1MB数据**：3us
- **从SSD顺序读取1MB数据**：49us
- **从磁盘顺序读取1MB数据**：718us
- SSD随机读：39us
- 磁盘寻址：2ms
- 数据包美国-欧洲RTT：150ms
- 总结
  - 内存读写 >> 磁盘读写
  - 顺序读写 >> 随机读写

# 分布式系统模型

## 两将军问题

- 问题描述：两个将军分别带领各自军队准备进攻一个城市，两个军队分别驻扎在由一个山谷隔开的两个山丘。两个军队传递消息的唯一途径是派遣信使穿越山谷，但山谷由城市守卫军占领，信使可能被俘。当且仅当两个军队同时进攻，攻打城市才能成功。请问在这种情况下，进攻城市有可能成功吗？

- 答案：两将军问题无解。两位将军总是会怀疑他们派遣的最后一位信使是否顺利穿过山谷到达另一山丘

## 拜占庭将军问题

- 问题描述
  - 三个军队A、B、C驻扎在三个营地，准备攻打城市。他们必须达成一致，共同决定进攻，或共同决定撤退
  - 但是，将军中可能出现叛徒，试图故意误导和迷惑其他将军来破坏整个军事行动
- 分析
  - 如果C收到来自A、B的消息，A决定进攻，B决定撤退，C无法分辨谁是叛徒
  - 将军A可能是叛徒：A告诉B撤退，告诉C进攻，即故意发送相互矛盾的消息
  - 将军B可能是叛徒：A告诉B、C进攻，B收到后仍然告诉C撤退
- **拜占庭故障模型**：分布式系统中，节点不仅可能发生故障或错误，甚至会故意篡改、破坏和控制系统的系统模型

## 系统模型

- 系统模型分为网络模型、节点故障模型、时间模型

### 网络链路模型

- 可靠链路：不会丢失消息，不会无中生有，没有重复，但可能对消息重新排序
- 公平损失链路：可能会丢失、重复或重新排序，但不会无中生有，且保证消息最终到达
- 任意链路：允许任意的网络链路执行任何操作
- 三种网络模型间的转化
  - 公平损失链路，通过不断重传丢失的消息并让接收者过滤重复消息，即可转化为可靠链路
  - 任意链路通过加密技术即可转化为公平损失链路

### 节点故障模型

- 崩溃-停止：节点停止工作后永远不会恢复（不能依赖于节点恢复）
- 崩溃-恢复：允许节点重新启动并继续执行剩余的步骤
- 拜占庭故障：故障节点不仅宕机，还可能以任意方式偏离算法，甚至恶意破坏系统

### 按时间划分系统模型

- 同步系统模型：一个消息的响应时间在一个有限且已知的时间范围内
- 异步系统模型：一个消息的响应时间是无限的，无法得知消息什么时候会到达
  - 网络延迟
  - 操作系统因为内存不足而挂起一个线程
  - GC暂停正在运行的线程（Stop The World）
- 部分同步系统模型：系统大部分时间是同步的，偶尔因为故障转变为异步系统

## 消息传递语义

- 最多一次At Most Once：消息最多传递一次，可能丢失，但不会重复
- 至少一次At Least Once：系统保证每条消息至少发送一次，不会丢失，但可能重复发送
- 精确一次Exact Once：消息只会被精确地传递一次，不丢失、不重复。实际上，通常实现的是**消息精确处理一次**，方法如给每条消息一个唯一的标识符等
- 幂等操作：多次操作产生相同结果，且不会有任何其他影响

> 本书默认的分布式系统模型是：可靠链路，考虑崩溃-停止/崩溃-恢复故障，部分同步系统模型

# 分布式数据基础

## 分区

- 分区：将一个数据集拆分为多个较小的数据集，并把存储和处理小数据集的责任分配给分布式系统的不同节点
- 垂直分区：对表的列进行拆分，如将不经常使用的列，或包含了大text类型，或BLOB类型的列垂直分区
- 水平分区：对表的行进行拆分
- 列式数据库：以列为单位进行数据存储架构的数据库，更适用于OLAP（联机分析处理）
- 行式数据库：更适用于OLTP（联机事务处理）

### 水平分区算法

#### 范围分区

- 概念：根据关键字将数据集拆分为若干连续范围，每个范围存储在一个节点上
- 分区划分：由管理员设定，或存储系统自行划分
- route：负载均衡节点接受客户端请求，并根据范围分区算法，确定请求重定向到哪个节点或哪几个节点
- 优点
  - 对用于范围分区的关键字进行范围查询
  - 进行范围查询时若位于同一个节点则性能好
  - 通过修改范围边界，能够简单有效地调整范围
- 缺点
  - 查询范围设计多个节点时，性能较差
  - 容易产生数据分布不均匀，或请求流量不均匀的问题，导致某些数据的热点现象，造成节点负载不均衡
- 示例：Google Bigtable，Apache HBase，PingCAP TiKV

#### 哈希分区

- 概念：将指定的关键字经过一个哈希函数的计算，根据哈希值决定该数据集的分区
- 优点：数据分布相对均匀
- 缺点
  - 不支持范围查询：不额外存储数据的情况下， 无法执行范围查询
  - 扩缩容成本高：添加或删除节点时，需要修改哈希函数，导致现有的许多数据需要重新映射，引起大范围数据移动，且移动期间服务可能暂停

#### 一致性哈希

- 优点：解决了哈希分区中，增删节点引起大规模数据移动的问题，具有更好的扩展性
- 哈希环：将哈希值组织为一个抽象的圆环，哈希值在[0, INT_MAX]之间，均匀地映射到哈希环上
- 数据分配：节点映射到哈希环上，数据存储在按照顺时针方向遇到的第一个节点上
- 增加节点：添加一台服务器，只会将一部分数据从旧服务器移动到新增服务器上，其他数据不会受到影响，无需修改哈希函数
- 缺点
  - 节点较少时，容易产生数据分配不均匀
  - 节点下线时，其数据移动到顺时针方向的节点上，导致大量负载会倾斜到该节点

- 虚拟节点

  - 一个物理节点并不对应哈希环中的一个点，而是对应多个节点。虚拟节点越多，数据分布越均匀

  - 如果系统中节点的机器性能不一样，则**性能高的物理节点映射出更多数量的虚拟节点**，促进负载均衡

### 分区的挑战

- 垂直分区：将不同表数据组合起来的查询（join）非常低效，因为需要访问多个节点的数据
- 水平分区：范围查询涉及的行可能位于多个节点，查询性能较低
- 事务：分布式系统中实现事务较为困难

## 复制

- 复制：同一份数据冗余存储在多个节点上，节点之间通过网络同步数据，保持一致
- 副本：存储了复制数据的节点称为副本（replica）
- 优点
  - 增加数据的可用性和安全性
  - 减少往返时间，将用户请求重定向到离用户更近的副本
  - 增加吞吐量
- 缺点
  - 增加复杂性，数据一致性迎来挑战

### 单主复制Single-Master

- Leader/Master/Primary：写请求必须由主节点处理
- Follower/Slave/Backup：从节点只能处理读请求，从主节点同步最新数据
- 同步数据的方式：同步复制、异步复制、半同步复制

#### 同步复制

- 主节点执行完写请求后，必须等待所有从节点都执行完毕，并收到确认信息后才能回复客户端写入成功
- 优点：数据可用性高，所有副本数据一致
- 缺点：性能低，任意一个节点负载过高导致请求处理速度慢，都将影响整个写请求

#### 异步复制

- 主节点执行写请求后，立刻回复客户端写入成功
- 缺点：数据一致性和持久性受影响
  - 一致性：写请求返回后，立刻往从节点发送读请求，若从节点未同步数据，则数据不一致
  - 持久性：若写请求返回后，主节点立刻宕机，写操作没有同步到任何从节点上，此时写操作丢失


#### 半同步复制

- 主节点执行写请求后，必须等待至少一个节点执行完毕并收到其确认信息，才能回复客户端写入成功

#### 单主复制优缺点

- 优点
  - 简单，易于实现
  - 仅在主节点执行写操作，保证操作的顺序
  - 读请求性能可通过增加从节点得到提升
- 缺点
  - 写请求性能瓶颈
  - 从节点提升为主节点的切换，会有一定的服务中断时间

### 多主复制Multi-Master

- 概念：多个master处理写请求
- 问题：数据冲突
- 解决数据冲突的方法
  - 由客户端解决数据冲突（购物车）
  - 最后写入胜利（每个写请求都有自增ID，难以维护统一的全局时间）
  - 因果关系跟踪（无法覆盖所有写请求）
  - 无冲突复制数据类型
- 优点
  - 增加主节点的容错性
  - 提升写请求性能
- 缺点：复杂性增加，数据冲突难以解决，甚至可能造成数据损坏

### 无主复制Leaderless

- 概念：写请求发送到多个节点上执行，读请求也从多个节点读取数据，并选取最新数据作为读的结果
- 写成功：客户端将写请求并发地发送给几个节点，一旦得到足够数量节点读确认响应，则认为写成功
- 协调请求方式
  - 客户端进行协调：客户端直接将写操作发送给多个副本
  - 协调节点coordinator：客户端将请求发送给协调节点，协调节点代表客户将写请求转发到多个副本，多个副本确认后再由协调节点响应客户端
- 冲突解决
  - **读修复**：客户端读到旧数据时，发送一个带有最新数据的写请求给旧数据所在节点
  - **反熵过程**：后台进程负责找出错误数据，并从最新的数据节点中将数据复制到错误的节点

- 无主复制只保证结果一致，不保证写操作的顺序

#### Quorum机制

- 系统中存在N个节点，写请求发送给W个节点，读请求发送给R个节点，若同时满足下列条件，则读取的R个返回值中最少包含一个最新的值

  - W + R > N
  - W > N / 2

- 参数配置：通过W与R的配置，可根据负载情况调节读写性能，W越大R越小，读性能越好，反之写性能越好

## CAP定理

- CAP定理：在一个异步网络环境中，对于一个分布式读写存储系统，只能满足以下三项中的两项，而不可能满足全部三项
  - **一致性Consistency**：线性一致性。客户端读取所有节点，返回的都是同一份最新的数据
  - **可用性Availability**：每次请求都能获得非错误的响应，但不保证获取的数据是最新数据
  - **分区容错性Partition Tolerance**：由于网络分区而导致消息丢失的情况下，系统仍能继续正常运行

- 反证法证明CAP定理
  - 假设系统由节点A、B组成，且同时满足CAP定理，当前值V=0，且A、B之间发生了网络分区
  - 客户端向A发起写请求，将V更新为1，根据可用性A将响应请求，但无法将数据复制到B，此时节点A处V=1，节点B处V=0
  - 客户端向B发起读请求，根据可用性B将响应请求，返回V=0，这违背了一致性。QED
- CAP定理对系统设计的意义
  - 网络分区故障是必然发生的，因此一般情况下需要保证分区容错性P
  - 在此基础上若选择保证一致性C，则分布式系统称为**CP系统**
  - 若选择保证可用性A，则分布式系统称为**AP系统**
- CAP定理的批评
  - 三选二公示存在误导性，实际上网络分区很少发生，因此当不发送网络分区时，可用性和一致性能够同时被满足
  - CAP定理的经典解释忽略了网络延迟，但实际上网络延迟也会影响可用性、一致性

### PACELC定理

- 延迟不可忽略：对CAP定理的扩展，指出延迟在系统运行过程中时刻存在，不可忽略
- 若存在网络分区P，则必须在可用性A和一致性C之间做出选择，即PA或PC；若不存在网络分区（E，Else），则必须在延迟L和一致性C之间做出选择，即EL或EC，分布式系统可总结为PA/PC与EL/EC之间的组合
- 大部分分布式系统属于PA/EL类型，或PC/EC类型

### BASE

- BASE：基本可用Basically Available、软状态Soft State、最终一致性Eventually Consistent
- 最终一致性：写数据时可能因为网络分区、延迟，导致数据没有同步到所有副本，系统中存在新旧数据，此时仍允许继续读写数据，系统保证**最终的某个时刻数据会同步到所有副本上**

## 一致性模型

- 可能提到的一致性
  - ACID中的一致性：数据库完整性约束，数据的一致性（如A+B=100为不变量）
  - CAP中的一致性：多个副本上的数据一致
  - raft、paxos等分布式一致性算法：实际上，正确的翻译应该是分布式共识算法
- 一致性模型：并发编程中系统和开发者之间的约定，如果开发者遵循某些规则，则读操作和写操作的结果是可预测的
  - 可预测：程序逻辑的确定性
  - 系统：可以是分布式系统，也可以指单机
  - 开发者：可以是客户端、分布式系统使用者、进程等
- 一致性模型本质上定义了**写操作的顺序和可见性**，即并发写操作执行的顺序如何，写操作的结果何时能被其他进程看见
- 按可用性分类的一致性模型
  - **不可用**：当系统发生网络分区时，为保证数据一致性，系统会不可用。如**线性一致性、顺序一致性**
  - **基本可用**：容忍一部分节点发生故障，还未故障的节点依然可用。如**因果一致性、PRAM一致性、读你所写一致性**
  - **高可用**：即时网络发生严重分区，没有故障的节点上仍然保证可用。如**读后写一致性、单调读一致性、单调写一致性**

### 线性一致性

- 线性一致性，也称为强一致性，来源于并发编程领域的概念
- 非严格定义：线性一致意味着分布式系统的所有操作看起来都是**原子**的，整个分布式系统看起来好像**只有一个节点**
- 执行历史：由一系列的调用事件和响应事件组成，若用线段代表读写操作，则线段左端点代表调用事件，右端点代表响应事件，线段长度代表操作执行时间
- 严格定义：给定一个**执行历史**，根据并发操作可以扩展为多个顺序历史，若能够从中找到一个**合法的顺序历史**，则该执行历史是线性一致性的
- 执行历史转化为顺序历史的原则
  - 顺序关系：一个操作明显在另一个操作之前发生
  - 并发关系：两个操作之间有重叠，或一个操作包含另一个操作
  - 顺序关系的两个操作，其先后关系必须保持不变
  - 并发关系的两个操作，可以以任何顺序排列

### 实现线性一致性

- 变量加锁解锁
- 原子比较-交换操作（CAS）
- 分布式系统通过**共识算法**实现线性一致性（如raft）

### 线性一致性的代价

- 并发编程中的同步原语和原子变量都会增加系统开销
- 分布式系统为保证线性一致性，需要全局时钟

### 顺序一致性

- 概念：只要求同一客户端的操作在排序后保持先后顺序不变，不同客户端之间的先后顺序可以任意改变
- 顺序一致性弱于线性一致性，它没有全局时间的限制，只关注局部的顺序

### 因果一致性

- 概念：必须以相同顺序看到因果相关的操作，没有因果关系的并发操作可以被不同进程以不同顺序观察到
- 示例：社交网络中发帖和评论的关系，发帖必然位于评论之前
- 微信朋友圈评论的因果一致性
  - 每条评论都有一个唯一且单调递增的数字ID，评论ID全局唯一（逻辑时钟）
  - 每条新评论的ID都必须比本地已见过的全局最大ID更大，确保因果关系
  - 广播本地看到的所有评论和新评论到其他数据中心，相同ID的评论合并排重

### 最终一致性

- 概念：在**最终的状态**下，只要不再执行写操作，读操作将返回相同的、最新的结果
- 某个阶段，系统各节点处理客户端的操作顺序可以不同，读操作也不需要返回最新的写操作的结果
- 使用最终一致性模型的分布式存储系统：Dynamo

### 以客户端为中心的一致性模型

- 以数据中心为中心的一致性模型：即上述线性一致性、顺序一致性、因果一致性等
- 以客户端为中心的一致性模型：以客户端的角度观察分布式系统，考虑客户端的读写请求结果，从而推断出系统的一致性
- 单调读一致性
- 单调写一致性
- 读你所写一致性
- PRAM一致性

## 隔离级别

- 隔离级别定义了并行系统中事务的结果何时、以何种方式对其他并发事务可见
- 常见隔离级别：串行化、可重复读、快照隔离、读已提交、读未提交
- 事务的基本用法：BEGIN开始事务，执行一系列操作，COMMIT提交事务，所有操作一并提交，事务要么成功，要么执行ROLLBACK回滚事务，放弃从事务开始的一切变更

### 并发系统可能出现的异常情况

- 脏写
  - 概念：一个事务覆盖了另一个仍在运行、尚未提交的事务写入的值
  - 问题：破坏数据的完整性约束，使系统无法正确回滚事务，一般需要防止脏写
- 脏读
  - 概念：一个事务读到了另一个尚未提交的事务写入的值
  - 问题：事务可能根据读到的值进行决策，若该尚未提交的事务进行回滚，则决策与系统的值是矛盾的
- 不可重复读：一个事务中查询一个值两次，得到的值不一样
- 幻读：一个事务进行条件查询时，另一个事务在中间插入或删除了匹配该条件的数据，导致两次条件查询读到的数据项变多了或变少了
- 更新丢失：两个事务读取同一个值，并试图将其更新为新的不同的值，则会发生更新丢失，导致只有一个更新生效
- 读偏斜（Read Skew）：读到了数据一致性约束被破坏的数据
- 写偏斜（Write Skew）：两个并发事务读到了相同的数据集，但随后各自修改了不相干的数据集，导致数据的一致性约束被破坏

### 不同隔离级别解决的问题

- 串行化：解决了所有问题，包括幻读
- 可重复读：脏写、脏读、不可重复读、更新丢失、读偏斜、写偏斜
- 快照隔离：脏写、脏读、不可重复读、更新丢失、读偏斜
- 已提交读：脏写、脏读
- 未提交读：脏写

## 一致性和隔离等级的对比

- 本质：描述系统容忍哪些行为，不能容忍哪些异常行为。更严格的一致性或隔离等级意味着更少的异常行为，但牺牲了可用性和性能
- 一致性模型适用于单个操作对象（单个数据项/变量）的读写，隔离级别通常涉及多个操作对象（事务修改多个数据项）
- 严格串行化：线性一致性 + 串行化
- Jepsen：一款用于系统测试的开源软件库，可用于评估分布式系统的正确性，对系统进行一致性验证

# 时间和事件顺序

## 物理时钟

- 物理时钟种类

  - 机械时钟：基于钟摆原理

  - 石英时钟：基于石英晶体

  - 原子钟：基于原子共振频率

- 时间标准

  - 世界时：以地球自转为基准
  - 国际原子时：以原子特性为标准

- UTC：基于国际原子时，世界时间标准

- NTP：一种网络时间协议，是UTC在互联网使用的一种方式

- 计算机时钟：使用石英钟，并基于NTP进行时钟同步

## 时钟同步

- 客户端/服务器架构：NTP服务器通过网络不断纠正多个NTP客户端的时钟

- 基本原理

  - 客户端发送一个NTP包，包含发送时间t0
  - 服务器收到NTP包后，填入接收包的时间t1
  - 服务器立即把响应包返回给客户端，填入发送包的时间t2
  - 客户端收到响应包时，记录时间t3，并解码取出包中的时间t0、t1、t2
  - **往返时延**$\delta=(t3-t2)+(t1-t0)$
  - 客户端应该设置的时间，即**时间偏移**$\theta=t2+\delta/2$

- 实际中，NTP客户端会定期轮询多个服务器，将计算得到的往返时延和时间偏移通过过滤器并统计分析，剔除异常值后从最好的三个候选结果中计算出时间偏移

- NTP时钟同步引发的程序错误

  ```go
  rtt := time.Now().Sub(start)
  // start是发送包时调用time.Now()获取的时间值, 接收响应包后再次调用time.Now()并减去start，便可以得到往返时延RTT
  ```

  - 以上代码看似合理，但在golang中time.Now()是读取本地当前时间的函数。如果两次调用之间计算机进行了NTP时钟同步，且时钟回拨，则可能导致计算的rtt为负值
  - 将一个负的rtt向下传递，可能引发系统性故障，这是Coludfare在2017年的一次故障原因

- 单调时钟

  - 概念：以某个时间点为起点，计算函数执行时经过的时间，以保证返回的时间严格单调增长

  - 解决了由于NTP时钟同步导致的rtt计算为负值等问题
  - 局限：只能在单机系统中使用，无法在分布式系统使用（因为只有来自一个节点的单调时钟才能以同样的时间点为起点）

## 逻辑时钟

### happens before关系

- happens before关系：如果事件a发生在事件b之前，即a->b
- happens before关系则满足以下三个规律
  - 如果事件a、b在同一个进程中，事件a发生在事件b之前，则a->b
  - 如果a是发送一条消息的事件，b是收到该消息的事件，则a->b
  - 如果a->b，且b->c，则a->c
- 如果两个事件a、b不满足a->b或b->a，则a、b两个事件是并发的，可以用a||b表示
- 时钟条件：如果两个事件a、b满足a->b，则C(a) < C(b)。反之并不成立。

### 逻辑时钟原理

- 逻辑时钟的计算方法
  - 每个进程都记录自己的逻辑时钟，初始值为0
  - 进程i发生一个新的事件，则将其逻辑时钟加1，Ci = Ci + 1
  - 进程i向进程j发送消息，进程i先将逻辑时钟加1，Ci = Ci + 1，然后将Ci和消息一起发送给进程j，**进程j更新自己的逻辑时钟为Cj = max(Ci, Cj) + 1**
- 逻辑时钟的特性
  - 无法得到完整的时间顺序，只能得到局部的先后顺序，无法得到全局的先后顺序
  - 逻辑时钟是偏序关系（Partial Ordering），物理时钟是全序关系（Total Ordering）
  - 全序关系：全部元素可比较，即集合中任意两个元素都是可以相互比较并确认大小关系的
  - 偏序关系：部分元素可以比较
- 将逻辑时钟的偏序关系扩展为全序关系
  - 给逻辑时钟附加进程编号Pi
  - 定义进程的全序关系，即进程的优先级，该优先级可由架构师根据实际情况任意定义

### 逻辑时钟应用

- 解决分布式互斥问题：一个分布式系统中，有多个进程和一个资源，进程需要互斥访问该资源，需要一种进程间同步算法来避免资源争抢
- 同步算法的要求
  - 资源需要互斥访问
  - 资源的授予顺序必须按照请求发送的顺序进行分配
  - 如果每个被授予资源的进程最终都释放了资源，那么每个请求最终都能够获得资源
- 消息内容：每个进程维护一个消息队列，消息内容为T0:P0，表示进程P0请求资源，请求时其逻辑时钟为T0
- 算法
  - 资源获取
    - 为了申请资源，进程Pi发送请求资源消息Tm:Pi给所有其他进程，并将消息放入自己的消息队列，Tm表示逻辑时钟
    - 进程Pj收到请求消息Tm:Pi时，将其放入自己的请求队列，并回复一个带有时间戳的ACK给进程Pi
    - 进程Pi获得资源，需要同时满足以下两个条件
      - 按照全序关系排序后，资源请求消息Tm:Pi排在进程Pi的消息队列的最前面
      - 进程Pi收到所有其他进程一条时间戳大于Tm的消息
  - 资源释放
    - 释放资源时，进程Pi将所有消息Tm:Pi从自己的消息队列中移除，并发送一条带有时间戳的释放资源消息给其他所有进程
    - 进程Pj收到Pi的释放资源消息，也将所有Tm:Pi消息从自己的消息队列移除
- 其他应用：Raft算法中，任期term扮演了逻辑时钟的角色

### 论文意义和局限性

- 提出了逻辑时钟模型
- 提出了任何一个分布式系统都可以被描述为一个特定顺序的状态机，不依赖于物理时钟，可用来解决网络延迟、网络分区和容错等问题
- 局限性：基于理想环境讨论，没有讨论消息丢失、消息重传如何处理等问题

## 向量时钟

- 向量时钟：在一个由N个节点组成的分布式系统中，每个节点的逻辑时钟的数据结构是N维向量，表示为[C0,C1,...Cn-1]。其中，第i个节点的向量表示为[Ci0,Ci1,...Cin-1]，Cii表示第i个节点自己的逻辑时钟
- 计算方法
  - 每个进程的向量时钟初始值全部为0
  - 如果进程i内部发生一个新的事件，则其自己的向量时钟加1，即Cii=Cii+1
  - 如果进程i向进程j发送消息，则进程i将自己的向量时钟加1，即Cii=Cii+1，同时将本地的向量时钟Ci和消息一起发送给进程j。进程j更新自己的向量时钟，对[0, N)上的每个整数k执行Cjk=max(Cik, Cjk)
- 向量时钟与逻辑时钟的区别
  - 更新逻辑时钟操作不同：收到消息时，除了更新自己的逻辑时钟，还要更新自己本地记录的所有节点的向量时钟
  - 判断happens before不同：如果a->b，则有
    - 对所有下标k，都有Cak <= Cbk
    - 在[0, N)中至少存在一个l，是的Cal <= Cbl
- 版本向量
  - 只关注改变了数据副本的事件，如更新数据操作
  - 发送者和接收者都需要同步更新其向量时钟
  - 计算方法
    - 每个节点的向量初始值全部为0
    - 节点i发生更新事件时，Vii=Vii+1
    - 节点i和节点j信息交换时，对[0, N)上的每一个整数k，执行Vik=Vjk=max(Vik, Vjk)
  - 应用：亚马逊的Dynamo架构使用版本向量检测数据冲突
- 缺点：向量维度至少是N，节点越多向量时钟越大，需要大量的磁盘和内存空间，且需要更长的时间来计算和比较

## 分布式快照

- 目的：通过一种方法获得系统的全局快照Global snapshot，也可以理解为全局状态Global state
- 挑战：分布式快照想要捕获整个系统的全局状态，但又不能让系统停止工作
- 分布式系统模型
  - 有向图：顶点代表节点或进程，边代表管道，节点通过管道发送和接收消息
  - 出边：发送消息的管道
  - 入边：接收消息的管道
  - 管道：容量无限大的队列
- 获取全局快照的算法
  - **初始化快照**：从进程Pi开始初始化快照，Pi记录自己的状态，并向其他所有进程发送maker消息，Pi记录自己所有入边Cji（j不等于i）收到的消息
  - **传播快照**：任意进程Pj从Ckj第一次收到marker消息时，Pj记录自身状态，同时将管道Ckj状态记为空，将marker消息广播给其他进程，并记录其他入边Clj（l不等于j或k）的消息，直到从该管道收到marker消息才停止记录
  - **终止快照**：所有进程都从所有入边收到了marker消息时，所有进程都记录了自己的快照。之后某个控制服务器收集每个进程的局部快照，构建出全局快照
